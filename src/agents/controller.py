"""
Controller - ç»“æœåˆæˆæ§åˆ¶å™¨
è´Ÿè´£æ•´åˆæ‰§è¡Œç»“æœã€ç”Ÿæˆæœ€ç»ˆå“åº”ã€å¤„ç†è¾“å‡ºæ ¼å¼åŒ–
"""

from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from ..config.settings import settings
from ..config.logging_config import get_logger
from ..config.llm_prompt_logger import log_llm_call
from .state import AgentState, OutputType
from ..output.template_match_service import get_template_match_service
from ..output.page_generator import get_page_generator
from ..output.dynamic_template_service import get_dynamic_template_service
from ..output.dynamic_page_generator import get_dynamic_page_generator
from ..utils.conversation_context_collector import create_collector_from_state

logger = get_logger(__name__)


# éœ€è¦è¿‡æ»¤çš„å·¥å…·åˆ—è¡¨ï¼ˆè¿™äº›å·¥å…·çš„ç»“æœä¸ä¼ é€’ç»™å“åº”åˆæˆLLMï¼‰
EXCLUDE_TOOLS_FROM_RESPONSE = [
    "login",           # ç™»å½•å·¥å…·ï¼Œè¿”å›tokenç­‰æ•æ„Ÿä¿¡æ¯
    "get_auth_token",  # è®¤è¯å·¥å…·
]

# éœ€è¦è¿‡æ»¤çš„æ•æ„Ÿå­—æ®µ
SENSITIVE_FIELDS = ["token", "password", "api_key", "secret"]

# éœ€è¦è½»é‡åŒ–å¤„ç†çš„å·¥å…·åˆ—è¡¨ï¼ˆè¿™äº›å·¥å…·è¿”å›å¤§é‡æ—¶åºæ•°æ®ï¼Œéœ€è¦æˆªå–éƒ¨åˆ†å€¼ï¼‰
# è½»é‡åŒ–å¤„ç†ï¼šå¯¹äºæ—¶åºæ•°æ®å­—å…¸ï¼Œåªä¿ç•™å‰å‡ ä¸ªå€¼ä½œä¸ºç¤ºä¾‹
LIGHTWEIGHT_TOOLS = [
    "get_tjdata_result",           # è·å–é¢„æŠ¥æ–¹æ¡ˆç»“æœï¼ŒåŒ…å«å¤§é‡æ—¶åºæ•°æ®
    "get_history_autoforcast_res", # è·å–å†å²è‡ªåŠ¨é¢„æŠ¥ç»“æœï¼ŒåŒ…å«å¤§é‡æ—¶åºæ•°æ®
]


# å“åº”ç”Ÿæˆæç¤ºè¯
RESPONSE_GENERATION_PROMPT = """ä½ æ˜¯å«å…±æµåŸŸæ•°å­—å­ªç”Ÿç³»ç»Ÿçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè´Ÿè´£ç”Ÿæˆæœ€ç»ˆå“åº”ã€‚

## æœ€è¿‘å¯¹è¯å†å²
{chat_history}

## ç”¨æˆ·åŸå§‹é—®é¢˜
{user_message}

## ç”¨æˆ·æ„å›¾
{intent}

## æ‰§è¡Œè®¡åˆ’
{plan_summary}

## æ‰§è¡Œç»“æœ
{execution_results}

## æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†
{retrieved_documents}

## è¾“å‡ºè¦æ±‚
1. ç»“åˆå¯¹è¯å†å²ç†è§£ç”¨æˆ·é—®é¢˜çš„å®Œæ•´å«ä¹‰ï¼ˆå¦‚ç”¨æˆ·è¯´"å°å—æµ·å‘¢ï¼Ÿ"ï¼Œéœ€ç»“åˆå†å²çŸ¥é“æ˜¯åœ¨é—®æµåŸŸé¢ç§¯ï¼‰
2. æ ¹æ®æ‰§è¡Œç»“æœï¼Œç”Ÿæˆæ¸…æ™°ã€å‡†ç¡®ã€ä¸“ä¸šçš„å›ç­”
3. å›ç­”åº”è¯¥ç®€æ´æ˜äº†ï¼Œç›´æ¥åˆ‡ä¸­ä¸»é¢˜ï¼Œçªå‡ºå…³é”®æ•°æ®å’Œç»“è®º
4. å¦‚æœæ‰§è¡Œè¿‡ç¨‹ä¸­æœ‰é”™è¯¯ï¼Œè¯·é€‚å½“è¯´æ˜å¹¶ç»™å‡ºå»ºè®®
5. ã€é‡è¦ã€‘å¦‚æœä½¿ç”¨äº†æ£€ç´¢åˆ°çš„çŸ¥è¯†ï¼Œå¿…é¡»åœ¨å›ç­”æœ«å°¾æ·»åŠ "å‚è€ƒæ¥æº"éƒ¨åˆ†ã€‚ç›´æ¥å¤åˆ¶ä¸Šé¢æ¯æ¡çŸ¥è¯†çš„"æ¥æºå¼•ç”¨æ ¼å¼"å­—æ®µå†…å®¹ä½œä¸ºæ¥æºé“¾æ¥ï¼Œä¸è¦ä¿®æ”¹æˆ–ç®€åŒ–ï¼

## æ ¼å¼ç¦æ­¢
- ã€ç¦æ­¢ã€‘ä¸è¦ä½¿ç”¨Markdownè¡¨æ ¼æ ¼å¼ï¼ˆå¦‚ | åˆ—1 | åˆ—2 | è¿™ç§æ ¼å¼ï¼‰
- ã€ç¦æ­¢ã€‘ä¸è¦ç½—åˆ—å¤§é‡æ•°æ®é¡¹ï¼Œè¡¨æ ¼å’Œè¯¦ç»†æ•°æ®åº”åœ¨å·¦ä¾§æŠ¥å‘Šé¡µé¢ä¸­å±•ç¤º
- ã€å»ºè®®ã€‘ä½¿ç”¨ç®€æ´çš„æ–‡å­—æè¿°æˆ–çŸ­åˆ—è¡¨ï¼ˆå¦‚"- é¡¹ç›®: å€¼"ï¼‰æ¥å‘ˆç°å…³é”®ä¿¡æ¯
- ã€å»ºè®®ã€‘å¦‚æœæ•°æ®è¾ƒå¤šï¼Œåªæå–æœ€å…³é”®çš„2-3ä¸ªæŒ‡æ ‡è¿›è¡Œè¯´æ˜ï¼Œå¹¶æç¤ºç”¨æˆ·æŸ¥çœ‹å·¦ä¾§æŠ¥å‘Šé¡µé¢è·å–å®Œæ•´ä¿¡æ¯

è¯·ç”Ÿæˆæœ€ç»ˆå›ç­”:
"""

# Webé¡µé¢ç”Ÿæˆå†³ç­–æç¤ºè¯
WEB_PAGE_DECISION_PROMPT = """æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œå†³å®šæ˜¯å¦éœ€è¦ç”ŸæˆWebé¡µé¢å±•ç¤ºç»“æœã€‚

## ç”¨æˆ·é—®é¢˜
{user_message}

## æ‰§è¡Œç»“æœ
{execution_results}

## åˆ¤æ–­æ ‡å‡†
éœ€è¦ç”ŸæˆWebé¡µé¢çš„æƒ…å†µ:
1. æŸ¥è¯¢ç»“æœåŒ…å«æ—¶åºæ•°æ®ï¼ˆå¦‚æ°´ä½ã€é›¨é‡ã€æµé‡å˜åŒ–ï¼‰
2. éœ€è¦å±•ç¤ºå›¾è¡¨ï¼ˆè¶‹åŠ¿å›¾ã€æŸ±çŠ¶å›¾ã€é¥¼å›¾ç­‰ï¼‰
3. æ•°æ®é‡è¾ƒå¤§ï¼Œéœ€è¦è¡¨æ ¼å±•ç¤º
4. åŒ…å«åœ°ç†ä¿¡æ¯éœ€è¦åœ°å›¾å±•ç¤º

ä¸éœ€è¦Webé¡µé¢çš„æƒ…å†µ:
1. ç®€å•çš„æ–‡å­—å›ç­”
2. å•ä¸ªæ•°å€¼æŸ¥è¯¢
3. çŸ¥è¯†é—®ç­”ç±»é—®é¢˜

è¯·è¿”å›JSONæ ¼å¼:
{{
    "need_web_page": true/false,
    "page_type": "chart/table/map/dashboard/none",
    "reason": "åˆ¤æ–­ç†ç”±"
}}
"""


class Controller:
    """ç»“æœåˆæˆæ§åˆ¶å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ§åˆ¶å™¨"""
        # æ€è€ƒæ¨¡å¼é…ç½®ï¼ˆç”¨äºQwen3ç­‰æ¨¡å‹ï¼Œéæµå¼è°ƒç”¨éœ€è®¾ç½®ä¸ºfalseï¼‰
        extra_body = {"enable_thinking": settings.llm_enable_thinking}

        # ç»“æœåˆæˆLLM
        synthesis_cfg = settings.get_synthesis_config()
        self.llm = ChatOpenAI(
            api_key=synthesis_cfg["api_key"],
            base_url=synthesis_cfg["api_base"],
            model=synthesis_cfg["model"],
            temperature=synthesis_cfg["temperature"],
            model_kwargs={"extra_body": extra_body}
        )

        # å“åº”ç”Ÿæˆé“¾
        self.response_prompt = ChatPromptTemplate.from_template(RESPONSE_GENERATION_PROMPT)
        self.response_chain = self.response_prompt | self.llm

        logger.info("Controlleråˆå§‹åŒ–å®Œæˆ")
    
    def prepare_response_context(self, state: AgentState) -> Dict[str, Any]:
        """
        å‡†å¤‡å“åº”ä¸Šä¸‹æ–‡æ•°æ®

        Args:
            state: å½“å‰æ™ºèƒ½ä½“çŠ¶æ€

        Returns:
            åŒ…å«æ‰€æœ‰ä¸Šä¸‹æ–‡æ•°æ®çš„å­—å…¸
        """
        # æ ¼å¼åŒ–æ‰§è¡Œç»“æœï¼ˆä¼ å…¥planç”¨äºè¿‡æ»¤å†…éƒ¨å·¥å…·ï¼‰
        execution_summary = self._format_execution_results(
            state.get('execution_results', []),
            state.get('plan', [])
        )

        # æ ¼å¼åŒ–è®¡åˆ’æ‘˜è¦ï¼ˆä¼ å…¥æ‰§è¡Œç»“æœä»¥æ¨æ–­æ­¥éª¤çŠ¶æ€ï¼‰
        plan_summary = self._format_plan_summary(
            state.get('plan', []),
            state.get('execution_results', [])
        )

        # æ ¼å¼åŒ–æ£€ç´¢æ–‡æ¡£
        docs_summary = self._format_documents(
            state.get('retrieved_documents', [])
        )

        # æ ¼å¼åŒ–èŠå¤©å†å²ï¼ˆé™åˆ¶æœ€è¿‘2è½®å¯¹è¯ï¼‰
        chat_history_str = self._format_chat_history(state.get('chat_history', []))

        # æ•´åˆæ‰€æœ‰æ‰§è¡Œç»“æœæ•°æ®ï¼ˆç”¨äºæ¨¡æ¿æ•°æ®å‡†å¤‡ï¼‰
        results = state.get('execution_results', [])
        combined_data = {}
        for result in results:
            if result.get('success'):
                output = result.get('output') or result.get('result')
                if isinstance(output, dict):
                    combined_data.update(output)

        return {
            "execution_summary": execution_summary,
            "plan_summary": plan_summary,
            "docs_summary": docs_summary,
            "chat_history_str": chat_history_str,
            "combined_data": combined_data,
            "results": results
        }

    async def generate_text_only(self, state: AgentState, context: Dict[str, Any]) -> str:
        """
        ä»…ç”Ÿæˆæ–‡å­—å›å¤ï¼ˆç‹¬ç«‹æ–¹æ³•ï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œï¼‰

        Args:
            state: å½“å‰æ™ºèƒ½ä½“çŠ¶æ€
            context: é¢„å…ˆå‡†å¤‡çš„ä¸Šä¸‹æ–‡æ•°æ®

        Returns:
            æ–‡å­—å›å¤å†…å®¹
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯å¤ç”¨çš„æ–‡å­—å›å¤
        results = context.get('results', [])
        if results:
            last_result = results[-1]
            last_output = last_result.get('output')
            if last_result.get('success') and isinstance(last_output, str) and len(last_output) > 20:
                logger.info("å¤ç”¨æ‰§è¡Œæ­¥éª¤ä¸­çš„LLMæ€»ç»“ï¼Œè·³è¿‡é‡å¤ç”Ÿæˆ")
                return last_output

        # å‡†å¤‡ä¸Šä¸‹æ–‡å˜é‡
        context_vars = {
            "chat_history": context.get('chat_history_str') or "æ— ",
            "user_message": state.get('user_message', ''),
            "intent": state.get('intent', 'unknown'),
            "plan_summary": context.get('plan_summary') or "æ— æ‰§è¡Œè®¡åˆ’",
            "execution_results": context.get('execution_summary') or "æ— æ‰§è¡Œç»“æœ",
            "retrieved_documents": context.get('docs_summary') or "æ— ç›¸å…³çŸ¥è¯†"
        }

        try:
            import time
            _start = time.time()
            response = await self.response_chain.ainvoke(context_vars)
            _elapsed = time.time() - _start

            # è®°å½•LLMè°ƒç”¨æ—¥å¿—
            full_prompt = RESPONSE_GENERATION_PROMPT.format(**context_vars)
            log_llm_call(
                step_name="æ–‡å­—å“åº”ç”Ÿæˆ",
                module_name="Controller.generate_text_only",
                prompt_template_name="RESPONSE_GENERATION_PROMPT",
                context_variables=context_vars,
                full_prompt=full_prompt,
                response=response.content,
                elapsed_time=_elapsed
            )

            logger.info("LLMç”Ÿæˆæ–‡å­—å›å¤æˆåŠŸ")
            return response.content

        except Exception as e:
            logger.warning(f"LLMç”Ÿæˆæ–‡å­—å›å¤å¤±è´¥: {e}")
            return f"æ ¹æ®æ‚¨çš„æŸ¥è¯¢ï¼Œç³»ç»Ÿå·²å®Œæˆå¤„ç†ã€‚\n\n{context.get('execution_summary', '')}"

    async def generate_page_only(self, state: AgentState, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä»…ç”Ÿæˆé¡µé¢ï¼ˆç‹¬ç«‹æ–¹æ³•ï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œï¼‰

        Args:
            state: å½“å‰æ™ºèƒ½ä½“çŠ¶æ€
            context: é¢„å…ˆå‡†å¤‡çš„ä¸Šä¸‹æ–‡æ•°æ®

        Returns:
            åŒ…å«é¡µé¢URLæˆ–é”™è¯¯ä¿¡æ¯çš„å­—å…¸
        """
        try:
            results = context.get('results', [])
            combined_data = context.get('combined_data', {})
            execution_summary = context.get('execution_summary', '')

            sub_intent = state.get('business_sub_intent', '')
            user_message = state.get('user_message', '')

            template_match_service = get_template_match_service()
            matched_template = await template_match_service.match_template(
                user_message=user_message,
                sub_intent=sub_intent,
                execution_results=results,
                execution_summary=execution_summary
            )

            # å¦‚æœåŒ¹é…åˆ°æ¨¡æ¿ä¸”ç½®ä¿¡åº¦è¶³å¤Ÿé«˜ï¼Œä½¿ç”¨æ¨¡æ¿ç”Ÿæˆé¡µé¢
            if matched_template and matched_template.get('confidence', 0) >= 0.7:
                logger.info(f"åŒ¹é…åˆ°æ¨¡æ¿: {matched_template.get('display_name')}, ç½®ä¿¡åº¦: {matched_template.get('confidence')}")

                # æ£€æŸ¥æ˜¯å¦ä¸ºåŠ¨æ€æ¨¡æ¿ä¸”æœ‰HTMLå†…å®¹ï¼ˆç›´æ¥å¤ç”¨ï¼‰
                if matched_template.get('is_dynamic') and matched_template.get('html_content'):
                    logger.info(f"å¤ç”¨åŠ¨æ€æ¨¡æ¿HTMLå†…å®¹: {matched_template.get('display_name')}")

                    page_generator = get_page_generator()
                    page_url = await page_generator.save_html_content(
                        html_content=matched_template['html_content'],
                        title=matched_template.get('page_title') or self._generate_page_title(state)
                    )

                    template_match_service.increment_use_count(matched_template.get('id'), success=True)
                    logger.info(f"åŠ¨æ€æ¨¡æ¿å¤ç”¨æˆåŠŸ: {page_url}")

                    return {
                        "page_url": page_url,
                        "template_used": matched_template.get('display_name'),
                        "template_reused": True,
                        "success": True
                    }

                # é¢„å®šä¹‰æ¨¡æ¿ï¼šä½¿ç”¨æ¨¡æ¿ç”Ÿæˆé¡µé¢
                template_data = self._prepare_template_data(state, combined_data, matched_template)

                page_generator = get_page_generator()
                page_url = await page_generator.generate_page_with_template(
                    template_info=matched_template,
                    data=template_data,
                    title=self._generate_page_title(state)
                )

                template_match_service.increment_use_count(matched_template.get('id'), success=True)
                logger.info(f"ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆé¡µé¢æˆåŠŸ: {page_url}")

                return {
                    "page_url": page_url,
                    "template_used": matched_template.get('display_name'),
                    "success": True
                }

            # æœªåŒ¹é…åˆ°æ¨¡æ¿ï¼Œä½¿ç”¨åŠ¨æ€ç”Ÿæˆ
            logger.info("æœªåŒ¹é…åˆ°é¢„å®šä¹‰æ¨¡æ¿ï¼Œä½¿ç”¨ DynamicPageGenerator åŠ¨æ€ç”Ÿæˆé¡µé¢")

            # åˆ›å»ºä¸Šä¸‹æ–‡æ”¶é›†å™¨
            collector = create_collector_from_state(state)

            # è·å–ç”Ÿæˆå™¨å®ä¾‹
            generator = get_dynamic_page_generator()

            # ç”Ÿæˆé¡µé¢
            page_url = await generator.generate(
                conversation_context=collector.to_frontend_format()
            )

            return {
                "page_url": page_url,
                "template_used": "dynamic_generated",
                "success": True
            }

        except Exception as e:
            logger.error(f"é¡µé¢ç”Ÿæˆå¤±è´¥: {e}")
            return {
                "page_url": None,
                "success": False,
                "error": str(e)
            }

    async def synthesize_response(self, state: AgentState) -> Dict[str, Any]:
        """
        åˆæˆæœ€ç»ˆå“åº”

        Args:
            state: å½“å‰æ™ºèƒ½ä½“çŠ¶æ€

        Returns:
            åŒ…å«æœ€ç»ˆå“åº”çš„çŠ¶æ€æ›´æ–°
        """
        logger.info("å¼€å§‹åˆæˆæœ€ç»ˆå“åº”...")

        try:
            # å‡†å¤‡ä¸Šä¸‹æ–‡æ•°æ®
            context = self.prepare_response_context(state)
            execution_summary = context['execution_summary']

            # æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å·²ç»ç”Ÿæˆäº†é¡µé¢URL
            workflow_page_url = state.get('generated_page_url')
            if workflow_page_url:
                logger.info(f"å·¥ä½œæµå·²ç”Ÿæˆé¡µé¢URL: {workflow_page_url}")
                # ç”Ÿæˆæ–‡å­—å›å¤
                text_response = await self._generate_text_response_for_workflow(state, execution_summary)
                return {
                    "output_type": OutputType.WEB_PAGE.value,
                    "final_response": text_response,
                    "generated_page_url": workflow_page_url,
                    "page_generating": False,
                    "next_action": "end"
                }

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”ŸæˆWebé¡µé¢
            output_type = state.get('output_type', 'text')

            # ä½¿ç”¨çŸ­è·¯æ±‚å€¼ï¼šå¦‚æœ output_type å·²ç»æ˜¯ web_pageï¼Œå°±ä¸éœ€è¦è°ƒç”¨ _should_generate_web_page
            if output_type == OutputType.WEB_PAGE.value:
                need_web_page = True
            else:
                need_web_page = await self._should_generate_web_page(state)

            if need_web_page:
                # éœ€è¦ç”ŸæˆWebé¡µé¢ - è¿”å›æ ‡è®°ï¼Œè®© graph å¹¶è¡Œå¤„ç†
                # å°†éœ€è¦çš„çŠ¶æ€å­—æ®µæ·»åŠ åˆ°è¿”å›å€¼ä¸­ï¼Œä¾› generate_page_only ä½¿ç”¨
                return {
                    "output_type": OutputType.WEB_PAGE.value,
                    "need_parallel_generation": True,
                    "response_context": context,
                    "next_action": "parallel_generate",
                    # ä¼ é€’ generate_page_only éœ€è¦çš„çŠ¶æ€å­—æ®µ
                    "business_sub_intent": state.get('business_sub_intent', ''),
                    "user_message": state.get('user_message', ''),
                    "forecast_target": state.get('forecast_target', {}),
                    "extracted_result": state.get('extracted_result', {}),
                    "workflow_context": state.get('workflow_context', {}),
                    "intent": state.get('intent', ''),
                    # ä¼ é€’æ–¹æ¡ˆIDï¼ˆæ‰€æœ‰å·¥ä½œæµç»Ÿä¸€è¾“å‡ºä¸º plan_idï¼‰
                    "plan_id": state.get('plan_id'),
                }

            # ä¸éœ€è¦é¡µé¢ï¼Œåªç”Ÿæˆæ–‡å­—å›å¤
            text_response = await self.generate_text_only(state, context)

            logger.info("å“åº”åˆæˆå®Œæˆï¼ˆçº¯æ–‡å­—ï¼‰")

            return {
                "output_type": OutputType.TEXT.value,
                "final_response": text_response,
                "next_action": "end"
            }

        except Exception as e:
            logger.error(f"å“åº”åˆæˆå¤±è´¥: {e}")
            return {
                "output_type": OutputType.TEXT.value,
                "final_response": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜: {str(e)}",
                "error": str(e),
                "next_action": "end"
            }
    
    async def _should_generate_web_page(self, state: AgentState) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦ç”ŸæˆWebé¡µé¢

        åŸºäºå†…å®¹è¯­ä¹‰åˆ¤æ–­ï¼Œè€Œéç®€å•çš„æ•°æ®ç»“æ„åˆ¤æ–­ã€‚

        ç”Ÿæˆé¡µé¢çš„æ¡ä»¶ï¼ˆæ»¡è¶³ä»»ä¸€ï¼‰ï¼š
        1. åŒ…å«æ—¶åºæ•°æ®ï¼ˆè¿‡ç¨‹æ›²çº¿ï¼‰
        2. åŒ…å«éœ€è¦å›¾è¡¨å±•ç¤ºçš„å¤šç»´æ•°æ®
        3. åŒ…å«åœ°ç†åæ ‡/åœ°å›¾æ•°æ®
        4. åŒ…å«å›¾ç‰‡/æ–‡ä»¶è·¯å¾„
        5. æ•°æ®é‡å¤§ï¼ˆåˆ—è¡¨>5æ¡è¡¨æ ¼æ•°æ®ï¼‰
        6. åŒ…å«é¢„æŠ¥/é¢„æµ‹ç»“æœ

        ä¸ç”Ÿæˆé¡µé¢çš„æ¡ä»¶ï¼š
        1. å•ä¸ªæ•°å€¼ç»“æœï¼ˆæ°´ä½ã€æµé‡ç­‰ï¼‰
        2. ç®€å•çš„æ˜¯/å¦åˆ¤æ–­
        3. çŸ­æ–‡æœ¬æè¿°
        4. çº¯æ–‡æœ¬çŸ¥è¯†åº“æ£€ç´¢ç»“æœ

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            æ˜¯å¦éœ€è¦ç”ŸæˆWebé¡µé¢
        """
        # 1. æ£€æŸ¥æ‰§è¡Œç»“æœï¼ˆæ„å›¾3ï¼šBUSINESSï¼‰
        execution_results = state.get('execution_results', [])
        for result in execution_results:
            output = result.get('output') or result.get('result')
            if self._check_need_web_page(output):
                logger.debug(f"æ£€æµ‹åˆ°éœ€è¦Webé¡µé¢å±•ç¤ºçš„æ•°æ®ï¼ˆæ¥è‡ªæ‰§è¡Œç»“æœï¼‰")
                return True

        # 2. æ£€æŸ¥çŸ¥è¯†åº“æ£€ç´¢ç»“æœï¼ˆæ„å›¾2ï¼šKNOWLEDGEï¼‰
        # çŸ¥è¯†åº“æ£€ç´¢ç»“æœé€šå¸¸æ˜¯çº¯æ–‡æœ¬ï¼Œä¸éœ€è¦é¡µé¢å±•ç¤º
        # ä½†å¦‚æœæ£€ç´¢åˆ°çš„å†…å®¹åŒ…å«ç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚è¡¨æ ¼ã€å›¾ç‰‡è·¯å¾„ç­‰ï¼‰ï¼Œåˆ™éœ€è¦é¡µé¢
        retrieved_documents = state.get('retrieved_documents', [])
        if retrieved_documents:
            # æ£€æŸ¥æ£€ç´¢ç»“æœæ•°é‡ï¼šå¦‚æœæ£€ç´¢åˆ°å¤§é‡æ–‡æ¡£ï¼ˆ>5æ¡ï¼‰ï¼Œå¯èƒ½éœ€è¦é¡µé¢å±•ç¤º
            if len(retrieved_documents) > 5:
                logger.debug(f"æ£€ç´¢åˆ°å¤§é‡æ–‡æ¡£ï¼ˆ{len(retrieved_documents)}æ¡ï¼‰ï¼Œå»ºè®®é¡µé¢å±•ç¤º")
                return True

            # æ£€æŸ¥æ–‡æ¡£å†…å®¹æ˜¯å¦åŒ…å«éœ€è¦é¡µé¢å±•ç¤ºçš„æ•°æ®
            for doc in retrieved_documents:
                content = doc.get('content', '')
                metadata = doc.get('metadata', {})

                # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡
                if metadata.get('has_images') or self._content_has_images(content):
                    logger.debug("æ£€ç´¢æ–‡æ¡£åŒ…å«å›¾ç‰‡ï¼Œéœ€è¦é¡µé¢å±•ç¤º")
                    return True

                # æ£€æŸ¥æ˜¯å¦åŒ…å«è¡¨æ ¼æ•°æ®ï¼ˆMarkdownè¡¨æ ¼æ ¼å¼ï¼‰
                if self._content_has_table(content):
                    logger.debug("æ£€ç´¢æ–‡æ¡£åŒ…å«è¡¨æ ¼ï¼Œéœ€è¦é¡µé¢å±•ç¤º")
                    return True

        return False

    def _content_has_images(self, content: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬å†…å®¹æ˜¯å¦åŒ…å«å›¾ç‰‡å¼•ç”¨"""
        if not content:
            return False
        # æ£€æŸ¥Markdownå›¾ç‰‡è¯­æ³•æˆ–å›¾ç‰‡è·¯å¾„
        image_patterns = ['![', '.png', '.jpg', '.jpeg', '.gif', '.svg', '.webp']
        content_lower = content.lower()
        return any(pattern in content_lower for pattern in image_patterns)

    def _content_has_table(self, content: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬å†…å®¹æ˜¯å¦åŒ…å«è¡¨æ ¼"""
        if not content:
            return False
        # æ£€æŸ¥Markdownè¡¨æ ¼è¯­æ³•ï¼ˆè‡³å°‘3è¡ŒåŒ…å«|åˆ†éš”ç¬¦ï¼‰
        lines = content.split('\n')
        table_lines = [line for line in lines if '|' in line and line.strip().startswith('|')]
        return len(table_lines) >= 3

    def _check_need_web_page(self, data: Any, depth: int = 0) -> bool:
        """
        é€’å½’æ£€æŸ¥æ•°æ®æ˜¯å¦éœ€è¦Webé¡µé¢å±•ç¤º

        Args:
            data: è¦æ£€æŸ¥çš„æ•°æ®
            depth: é€’å½’æ·±åº¦ï¼Œé˜²æ­¢æ— é™é€’å½’

        Returns:
            æ˜¯å¦éœ€è¦Webé¡µé¢
        """
        if depth > 5:  # é˜²æ­¢è¿‡æ·±é€’å½’
            return False

        # 1. ç©ºå€¼æˆ–ç®€å•ç±»å‹ - ä¸éœ€è¦é¡µé¢
        if data is None:
            return False
        if isinstance(data, bool):
            return False
        if isinstance(data, (int, float)):
            return False
        if isinstance(data, str):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡è·¯å¾„
            if self._is_image_path(data):
                return True
            # çŸ­æ–‡æœ¬ä¸éœ€è¦é¡µé¢
            return False

        # 2. åˆ—è¡¨ç±»å‹
        if isinstance(data, list):
            if len(data) == 0:
                return False
            # è¡¨æ ¼æ•°æ®ï¼šåˆ—è¡¨ä¸­çš„å…ƒç´ æ˜¯å­—å…¸ï¼Œä¸”é•¿åº¦>5
            if len(data) > 5 and isinstance(data[0], dict):
                return True
            # æ—¶åºæ•°æ®ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶é—´å­—æ®µ
            if len(data) > 3 and isinstance(data[0], dict):
                if self._has_time_series_fields(data[0]):
                    return True
            # é€’å½’æ£€æŸ¥åˆ—è¡¨å…ƒç´ 
            for item in data[:10]:  # åªæ£€æŸ¥å‰10ä¸ªå…ƒç´ 
                if self._check_need_web_page(item, depth + 1):
                    return True
            return False

        # 3. å­—å…¸ç±»å‹
        if isinstance(data, dict):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«éœ€è¦å›¾è¡¨å±•ç¤ºçš„å…³é”®å­—æ®µ
            if self._has_chart_data_fields(data):
                return True
            # æ£€æŸ¥æ˜¯å¦åŒ…å«åœ°å›¾æ•°æ®
            if self._has_map_data_fields(data):
                return True
            # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æŠ¥/é¢„æµ‹æ•°æ®
            if self._has_forecast_fields(data):
                return True
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡
            if self._has_image_fields(data):
                return True
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶åºæ•°æ®å­—å…¸
            if self._has_timeseries_dict_values(data):
                return True
            # é€’å½’æ£€æŸ¥å­—å…¸å€¼
            for key, value in data.items():
                if self._check_need_web_page(value, depth + 1):
                    return True
            return False

        return False

    def _has_time_series_fields(self, data: dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶åºæ•°æ®å­—æ®µ"""
        time_fields = {'time', 'datetime', 'date', 'timestamp', 'tm', 'dt',
                       'æ—¶é—´', 'æ—¥æœŸ', 'TM', 'DATETIME'}
        value_fields = {'value', 'values', 'z', 'q', 'p', 'water_level', 'flow',
                        'rainfall', 'æ°´ä½', 'æµé‡', 'é›¨é‡', 'Z', 'Q', 'P'}

        keys_lower = {str(k).lower() for k in data.keys()}
        keys_original = set(str(k) for k in data.keys())
        all_keys = keys_lower | keys_original

        has_time = bool(time_fields & all_keys)
        has_value = bool(value_fields & all_keys)

        return has_time and has_value

    def _has_chart_data_fields(self, data: dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾è¡¨æ•°æ®å­—æ®µ"""
        chart_fields = {'series', 'datasets', 'chart_data', 'xaxis', 'yaxis',
                        'categories', 'legend', 'echarts', 'chart'}
        keys_lower = {str(k).lower() for k in data.keys()}
        return bool(chart_fields & keys_lower)

    def _has_map_data_fields(self, data: dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«åœ°å›¾æ•°æ®å­—æ®µ"""
        map_fields = {'lat', 'lng', 'latitude', 'longitude', 'coordinates',
                      'coord', 'latlng', 'geo', 'geometry',
                      'ç»åº¦', 'çº¬åº¦', 'lgtd', 'lttd'}
        keys_lower = {str(k).lower() for k in data.keys()}
        return bool(map_fields & keys_lower)

    def _has_forecast_fields(self, data: dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æŠ¥/é¢„æµ‹æ•°æ®å­—æ®µ"""
        forecast_fields = {'forecast', 'prediction', 'predicted', 'forecast_data',
                          'forecast_result', 'predict_result', 'é¢„æŠ¥', 'é¢„æµ‹',
                          'future', 'expected', 'projected',
                          # æ°´æ–‡é¢„æŠ¥ç‰¹æœ‰å­—æ®µ
                          'max_inq', 'max_outq', 'max_level', 'max_qischarge',
                          'inq_dic', 'outq_dic', 'level_dic', 'q_dic', 'z_dic'}
        keys_lower = {str(k).lower() for k in data.keys()}
        return bool(forecast_fields & keys_lower)

    def _has_image_fields(self, data: dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡å­—æ®µ"""
        image_fields = {'image', 'img', 'picture', 'photo', 'image_url',
                        'img_url', 'thumbnail', 'å›¾ç‰‡', 'å›¾åƒ'}
        keys_lower = {str(k).lower() for k in data.keys()}
        if image_fields & keys_lower:
            return True

        # æ£€æŸ¥å€¼æ˜¯å¦ä¸ºå›¾ç‰‡è·¯å¾„
        for value in data.values():
            if isinstance(value, str) and self._is_image_path(value):
                return True
        return False

    def _has_timeseries_dict_values(self, data: dict) -> bool:
        """æ£€æŸ¥å­—å…¸å€¼ä¸­æ˜¯å¦åŒ…å«æ—¶åºæ•°æ®å­—å…¸ï¼ˆå¦‚ InQ_Dic, Level_Dic ç­‰ï¼‰"""
        timeseries_key_patterns = {'_dic', 'dic_', 'series', 'history', 'process'}
        for key, value in data.items():
            key_lower = str(key).lower()
            # æ£€æŸ¥é”®åæ˜¯å¦ç¬¦åˆæ—¶åºæ•°æ®æ¨¡å¼
            if any(pattern in key_lower for pattern in timeseries_key_patterns):
                if isinstance(value, dict) and len(value) > 3:
                    return True
        return False

    def _is_image_path(self, path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡è·¯å¾„"""
        image_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.svg', '.webp'}
        path_lower = path.lower()
        return any(path_lower.endswith(ext) for ext in image_extensions)

    def _prepare_template_data(
        self,
        state: AgentState,
        combined_data: Dict[str, Any],
        template_info: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        å‡†å¤‡æ¨¡æ¿æ‰€éœ€çš„æ•°æ®

        æ ¹æ®æ¨¡æ¿ç±»å‹å’Œæ‰§è¡Œç»“æœï¼Œæ„å»ºç¬¦åˆæ¨¡æ¿è¦æ±‚çš„æ•°æ®ç»“æ„ã€‚
        åŒ…å«é¢„å®šä¹‰æ¨¡æ¿æ‰€éœ€çš„å…³é”®å‚æ•°ï¼ˆplanCode, token, stcd ç­‰ï¼‰ã€‚

        Args:
            state: å½“å‰çŠ¶æ€
            combined_data: åˆå¹¶åçš„æ‰§è¡Œç»“æœæ•°æ®
            template_info: æ¨¡æ¿ä¿¡æ¯

        Returns:
            æ¨¡æ¿æ•°æ®å­—å…¸
        """
        template_name = template_info.get('name', '')
        forecast_target = state.get('forecast_target', {})
        extracted_result = state.get('extracted_result', {})
        workflow_context = state.get('workflow_context', {})

        # åŸºç¡€æ•°æ®
        data = {
            "user_message": state.get('user_message', ''),
            "intent": state.get('intent', ''),
            "sub_intent": state.get('business_sub_intent', ''),
        }

        # ä» workflow_context ä¸­æå–å…³é”®å‚æ•°ï¼ˆç”¨äºé¢„å®šä¹‰æ¨¡æ¿ï¼‰
        # workflow_context å¯èƒ½æœ‰å¤šç§ç»“æ„ï¼š
        # 1. ctx ç»“æ„: {'auth_token': ..., 'results': {...}, 'context_data': {'steps': {...}}}
        # 2. context_data ç»“æ„: {'inputs': {}, 'steps': {...}, 'state': {}}
        steps_data = {}
        if isinstance(workflow_context, dict):
            # å°è¯•ä» context_data.steps è·å–ï¼ˆctx ç»“æ„ï¼‰
            if 'context_data' in workflow_context:
                steps_data = workflow_context.get('context_data', {}).get('steps', {})
            # å°è¯•ç›´æ¥ä» steps è·å–ï¼ˆcontext_data ç»“æ„ï¼‰
            elif 'steps' in workflow_context:
                steps_data = workflow_context.get('steps', {})

            # å¦‚æœ steps_data ä¸ºç©ºï¼Œå°è¯•ä» results ä¸­æå– token
            if not steps_data.get('login') and 'results' in workflow_context:
                results = workflow_context.get('results', {})
                if results.get('auth_token'):
                    data['token'] = results['auth_token']

        # æå– token
        login_data = steps_data.get('login', {})
        if login_data.get('token'):
            data['token'] = login_data['token']

        # æå– planCodeï¼ˆæ‰€æœ‰å·¥ä½œæµç»Ÿä¸€è¾“å‡ºä¸º plan_idï¼‰
        plan_id = state.get('plan_id')
        logger.info(f"æå– planCode: plan_id={plan_id}")
        if plan_id:
            data['planCode'] = plan_id
        else:
            # å›é€€ï¼šå°è¯•ä» steps_data ä¸­è·å–
            forecast_step = steps_data.get('forecast', {})
            if forecast_step.get('planCode'):
                data['planCode'] = forecast_step['planCode']

        # æ ¹æ®æ¨¡æ¿ç±»å‹å‡†å¤‡æ•°æ®
        if template_name in ['res_flood_forecast', 'res_flood_resultshow']:
            # æ°´åº“æ´ªæ°´é¢„æŠ¥æ¨¡æ¿
            target_name = forecast_target.get('name', 'ç›˜çŸ³å¤´æ°´åº“')
            data["reservoirName"] = target_name
            data["reservoir_name"] = target_name

            # ä» extracted_result æˆ– combined_data è·å–æ°´åº“é¢„æŠ¥æ•°æ®
            if extracted_result and extracted_result.get('data'):
                reservoir_data = extracted_result.get('data', {})
            else:
                # å°è¯•ä» combined_data ä¸­æå–
                reservoir_result = combined_data.get('reservoir_result', {})
                reservoir_data = reservoir_result.get(target_name, {})

            data["data"] = reservoir_data
            data["reservoir_result"] = reservoir_data
            data["result_desc"] = extracted_result.get('summary', '') or combined_data.get('result_desc', '')

            # æå– stcd
            if reservoir_data.get('Stcd'):
                data['stcd'] = reservoir_data['Stcd']

            # é™é›¨æ•°æ®
            data["rain_data"] = combined_data.get('rain_data', [])

        elif template_name == 'station_flood_forecast':
            # ç«™ç‚¹æ´ªæ°´é¢„æŠ¥æ¨¡æ¿
            target_name = forecast_target.get('name', '')
            data["station_name"] = target_name

            if extracted_result and extracted_result.get('data'):
                data["station_result"] = extracted_result.get('data', {})
            else:
                data["station_result"] = combined_data.get('station_result', {})

            data["result_desc"] = extracted_result.get('summary', '')

        elif template_name == 'detention_basin_forecast':
            # è“„æ»æ´ªåŒºé¢„æŠ¥æ¨¡æ¿
            target_name = forecast_target.get('name', '')
            data["detention_name"] = target_name

            if extracted_result and extracted_result.get('data'):
                data["detention_result"] = extracted_result.get('data', {})
            else:
                data["detention_result"] = combined_data.get('detention_result', {})

            data["result_desc"] = extracted_result.get('summary', '')

        else:
            # é€šç”¨æ¨¡æ¿ï¼šç›´æ¥ä¼ é€’åˆå¹¶æ•°æ®
            data.update(combined_data)
            if extracted_result:
                data["extracted_result"] = extracted_result

        return data

    def _generate_page_title(self, state: AgentState) -> str:
        """
        ç”Ÿæˆé¡µé¢æ ‡é¢˜

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            é¡µé¢æ ‡é¢˜
        """
        forecast_target = state.get('forecast_target', {})
        target_name = forecast_target.get('name', '')
        intent = state.get('intent', '')
        sub_intent = state.get('business_sub_intent', '')

        if target_name:
            if 'forecast' in sub_intent or 'é¢„æŠ¥' in intent:
                return f"{target_name}æ´ªæ°´é¢„æŠ¥ç»“æœ"
            else:
                return f"{target_name}æŸ¥è¯¢ç»“æœ"

        if intent:
            return f"{intent}æŠ¥å‘Š"

        return "æŸ¥è¯¢ç»“æœæŠ¥å‘Š"

    async def _generate_text_response_for_workflow(
        self,
        state: AgentState,
        execution_summary: str
    ) -> str:
        """
        ä¸ºå·¥ä½œæµç”Ÿæˆæ–‡å­—å›å¤

        å½“å·¥ä½œæµå·²ç»ç”Ÿæˆäº†é¡µé¢URLæ—¶ï¼Œåªéœ€è¦ç”Ÿæˆæ–‡å­—å›å¤ã€‚

        Args:
            state: å½“å‰çŠ¶æ€
            execution_summary: æ‰§è¡Œç»“æœæ‘˜è¦

        Returns:
            æ–‡å­—å›å¤
        """
        # æ£€æŸ¥å·¥ä½œæµç»“æœä¸­æ˜¯å¦æœ‰æå–çš„æ•°æ®
        extracted_result = state.get('extracted_result', {})
        forecast_target = state.get('forecast_target', {})

        logger.info(f"ç”Ÿæˆå·¥ä½œæµæ–‡å­—å›å¤ - extracted_resultå­˜åœ¨: {bool(extracted_result)}, forecast_target: {forecast_target}")

        # å¦‚æœæœ‰æå–çš„ç»“æœï¼ŒåŸºäºç»“æœç”Ÿæˆå›å¤
        if extracted_result:
            target_name = forecast_target.get('name', 'ç›®æ ‡')
            target_type = forecast_target.get('type', 'basin')
            summary = extracted_result.get('summary', '')
            data = extracted_result.get('data', {})

            logger.info(f"æå–ç»“æœ - summary: {summary}, dataå­˜åœ¨: {bool(data)}, dataæœ‰message: {data.get('message') if data else None}")

            # æ„å»ºæ ¼å¼åŒ–çš„æ–‡å­—å›å¤
            if data and not data.get('message'):
                # æœ‰æœ‰æ•ˆæ•°æ®ï¼Œç”Ÿæˆæ ¼å¼åŒ–å›å¤
                result = self._format_forecast_response(target_name, target_type, summary, data)
                logger.info(f"ç”Ÿæˆçš„æ–‡å­—å›å¤: {result[:100]}...")
                return result
            elif data.get('message'):
                # æœ‰é”™è¯¯æ¶ˆæ¯
                return data.get('message')

        # ä½¿ç”¨LLMç”Ÿæˆå›å¤
        logger.info("extracted_resultä¸ºç©ºæˆ–æ— æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨LLMç”Ÿæˆå›å¤")
        try:
            chat_history_str = self._format_chat_history(state.get('chat_history', []))
            docs_summary = self._format_documents(state.get('retrieved_documents', []))

            context_vars = {
                "chat_history": chat_history_str or "æ— ",
                "user_message": state.get('user_message', ''),
                "intent": state.get('intent', 'unknown'),
                "plan_summary": "å·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                "execution_results": execution_summary or "æ— æ‰§è¡Œç»“æœ",
                "retrieved_documents": docs_summary or "æ— ç›¸å…³çŸ¥è¯†"
            }

            import time
            _start = time.time()
            response = await self.response_chain.ainvoke(context_vars)
            _elapsed = time.time() - _start

            full_prompt = RESPONSE_GENERATION_PROMPT.format(**context_vars)
            log_llm_call(
                step_name="å·¥ä½œæµå“åº”åˆæˆ",
                module_name="Controller._generate_text_response_for_workflow",
                prompt_template_name="RESPONSE_GENERATION_PROMPT",
                context_variables=context_vars,
                full_prompt=full_prompt,
                response=response.content,
                elapsed_time=_elapsed
            )

            return response.content

        except Exception as e:
            logger.warning(f"LLMç”Ÿæˆå›å¤å¤±è´¥: {e}")
            return f"å·²å®ŒæˆæŸ¥è¯¢ï¼Œè¯¦ç»†ç»“æœè¯·æŸ¥çœ‹å³ä¾§æŠ¥å‘Šé¡µé¢ã€‚"

    def _format_forecast_response(
        self,
        target_name: str,
        target_type: str,
        summary: str,
        data: Dict[str, Any]
    ) -> str:
        """
        æ ¼å¼åŒ–é¢„æŠ¥ç»“æœä¸ºæ–‡å­—å›å¤

        Args:
            target_name: ç›®æ ‡åç§°ï¼ˆå¦‚æ°´åº“åã€ç«™ç‚¹åï¼‰
            target_type: ç›®æ ‡ç±»å‹ï¼ˆreservoir/station/detention_basin/basin/multipleï¼‰
            summary: æ‘˜è¦ä¿¡æ¯
            data: é¢„æŠ¥æ•°æ®

        Returns:
            æ ¼å¼åŒ–çš„æ–‡å­—å›å¤
        """
        lines = [f"**{summary}**\n"]

        # å¤šå¯¹è±¡æŸ¥è¯¢ç»“æœï¼ˆæ”¯æŒ targets å’Œ results ä¸¤ç§æ ¼å¼ï¼‰
        if target_type == 'multiple':
            items = data.get('targets') or data.get('results') or []
            if items:
                for result_item in items:
                    item_data = result_item.get('data', {})
                    # å…¼å®¹ä¸¤ç§æ ¼å¼ï¼šç›´æ¥çš„ name/type æˆ–åµŒå¥—çš„ target.name/target.type
                    item_name = result_item.get('name') or result_item.get('target', {}).get('name', 'æœªçŸ¥å¯¹è±¡')
                    item_type = result_item.get('type') or result_item.get('target', {}).get('type', 'basin')

                    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯æ¶ˆæ¯
                    if item_data.get('message'):
                        lines.append(f"\nâš ï¸ **{item_name}**ï¼š{item_data.get('message')}")
                        continue

                    # æ ¹æ®ç±»å‹æ ¼å¼åŒ–å•ä¸ªå¯¹è±¡çš„ç»“æœ
                    single_lines = self._format_single_target_response(item_name, item_type, item_data)
                    lines.extend(single_lines)

                lines.append("\nğŸ’¡ *è¯¦ç»†ä¿¡æ¯å’Œè¿‡ç¨‹æ›²çº¿è¯·æŸ¥çœ‹å·¦ä¾§æŠ¥å‘Šé¡µé¢ã€‚*")
                return "\n".join(lines)

        if target_type == 'reservoir':
            # æ°´åº“é¢„æŠ¥ç»“æœæ ¼å¼åŒ–
            lines.append(f"ğŸ“Š **{target_name}é¢„æŠ¥æ•°æ®ï¼š**\n")

            # å…¥åº“æµé‡ä¿¡æ¯
            inflow_peak = data.get('Max_InQ') or data.get('inflow_peak') or data.get('å…¥åº“æ´ªå³°æµé‡')
            inflow_peak_time = data.get('MaxInQ_Time') or data.get('inflow_peak_time') or data.get('å…¥åº“æ´ªå³°æ—¶é—´')
            if inflow_peak is not None:
                lines.append(f"- **å…¥åº“æ´ªå³°æµé‡**ï¼š{inflow_peak} mÂ³/s")
                if inflow_peak_time:
                    lines.append(f"- **å…¥åº“æ´ªå³°æ—¶é—´**ï¼š{inflow_peak_time}")

            # å‡ºåº“æµé‡ä¿¡æ¯
            outflow_peak = data.get('Max_OutQ') or data.get('outflow_peak') or data.get('å‡ºåº“æ´ªå³°æµé‡')
            outflow_peak_time = data.get('MaxOutQ_Time') or data.get('outflow_peak_time') or data.get('å‡ºåº“æ´ªå³°æ—¶é—´')
            if outflow_peak is not None:
                lines.append(f"- **å‡ºåº“æ´ªå³°æµé‡**ï¼š{outflow_peak} mÂ³/s")
                if outflow_peak_time:
                    lines.append(f"- **å‡ºåº“æ´ªå³°æ—¶é—´**ï¼š{outflow_peak_time}")

            # æ°´ä½ä¿¡æ¯
            max_level = data.get('Max_Level') or data.get('max_water_level') or data.get('æœ€é«˜æ°´ä½')
            max_level_time = data.get('MaxLevel_Time') or data.get('max_water_level_time') or data.get('æœ€é«˜æ°´ä½æ—¶é—´')
            if max_level is not None:
                lines.append(f"- **æœ€é«˜æ°´ä½**ï¼š{max_level} m")
                if max_level_time:
                    lines.append(f"- **æœ€é«˜æ°´ä½æ—¶é—´**ï¼š{max_level_time}")

            # è“„æ°´é‡ä¿¡æ¯
            max_storage = data.get('Max_Volumn') or data.get('max_storage') or data.get('æœ€å¤§è“„æ°´é‡')
            if max_storage is not None:
                lines.append(f"- **æœ€å¤§è“„æ°´é‡**ï¼š{max_storage} ä¸‡mÂ³")

            # æ€»å…¥åº“é‡å’Œæ€»å‡ºåº“é‡
            total_inflow = data.get('Total_InVolumn') or data.get('æ€»å…¥åº“é‡')
            total_outflow = data.get('Total_OutVolumn') or data.get('æ€»å‡ºåº“é‡')
            if total_inflow is not None:
                lines.append(f"- **æ€»å…¥åº“é‡**ï¼š{total_inflow} ä¸‡mÂ³")
            if total_outflow is not None:
                lines.append(f"- **æ€»å‡ºåº“é‡**ï¼š{total_outflow} ä¸‡mÂ³")

            # é¢„æŠ¥ç»“æŸæ—¶çŠ¶æ€
            end_level = data.get('EndTime_Level') or data.get('é¢„æŠ¥ç»“æŸæ°´ä½')
            end_storage = data.get('EndTime_Volumn') or data.get('é¢„æŠ¥ç»“æŸè“„æ°´é‡')
            if end_level is not None or end_storage is not None:
                lines.append(f"\nğŸ“ˆ **é¢„æŠ¥ç»“æŸæ—¶çŠ¶æ€ï¼š**")
                if end_level is not None:
                    lines.append(f"- **æ°´ä½**ï¼š{end_level} m")
                if end_storage is not None:
                    lines.append(f"- **è“„æ°´é‡**ï¼š{end_storage} ä¸‡mÂ³")

        elif target_type == 'station':
            # ç«™ç‚¹é¢„æŠ¥ç»“æœæ ¼å¼åŒ–
            lines.append(f"ğŸ“Š **{target_name}é¢„æŠ¥æ•°æ®ï¼š**\n")

            # æ ¹æ®APIè¿”å›çš„å­—æ®µåè·å–æ•°æ®
            # APIå­—æ®µ: Max_Qischarge, MaxQ_AtTime, Max_Level, Total_Flood, Stcd, SectionName
            peak_flow = data.get('Max_Qischarge') or data.get('peak_flow') or data.get('æ´ªå³°æµé‡')
            peak_time = data.get('MaxQ_AtTime') or data.get('peak_time') or data.get('æ´ªå³°æ—¶é—´')
            peak_level = data.get('Max_Level') or data.get('peak_level') or data.get('æ´ªå³°æ°´ä½')
            total_flood = data.get('Total_Flood') or data.get('æ€»è¿‡æ´ªé‡')
            stcd = data.get('Stcd')
            section_name = data.get('SectionName')

            if section_name:
                lines.append(f"- **æ–­é¢åç§°**ï¼š{section_name}")
            if stcd:
                lines.append(f"- **ç«™ç‚¹ç¼–ç **ï¼š{stcd}")
            if peak_flow is not None:
                lines.append(f"- **æ´ªå³°æµé‡**ï¼š{peak_flow} mÂ³/s")
            if peak_time:
                lines.append(f"- **æ´ªå³°åˆ°è¾¾æ—¶é—´**ï¼š{peak_time}")
            if peak_level is not None:
                lines.append(f"- **æœ€é«˜æ°´ä½**ï¼š{peak_level} m")
            if total_flood is not None:
                lines.append(f"- **æ€»è¿‡æ´ªé‡**ï¼š{total_flood} ä¸‡mÂ³")

        elif target_type == 'detention_basin':
            # è“„æ»æ´ªåŒºé¢„æŠ¥ç»“æœæ ¼å¼åŒ–
            lines.append(f"ğŸ“Š **{target_name}é¢„æŠ¥æ•°æ®ï¼š**\n")

            # æ˜¾ç¤ºæ‰€æœ‰éæ—¶åºæ•°æ®å­—æ®µ
            skip_keys = {'message', 'InQ_Dic', 'OutQ_Dic', 'Level_Dic', 'Volumn_Dic',
                        'YHDOutQ_Dic', 'XHDOutQ_Dic'}
            for key, value in data.items():
                if key not in skip_keys and not isinstance(value, dict):
                    lines.append(f"- **{key}**ï¼š{value}")

        else:
            # å…¨æµåŸŸæˆ–å…¶ä»–ç±»å‹
            lines.append(f"ğŸ“Š **é¢„æŠ¥æ•°æ®ï¼š**\n")

            # å¤„ç†æ°´åº“ç»“æœ
            reservoir_result = data.get('reservoir_result', {})
            if reservoir_result:
                for res_name, res_data in reservoir_result.items():
                    lines.append(f"\nğŸï¸ **{res_name}ï¼š**")
                    if isinstance(res_data, dict):
                        max_level = res_data.get('Max_Level')
                        max_inq = res_data.get('Max_InQ')
                        max_outq = res_data.get('Max_OutQ')
                        if max_level is not None:
                            lines.append(f"- æœ€é«˜æ°´ä½ï¼š{max_level} m")
                        if max_inq is not None:
                            lines.append(f"- å…¥åº“æ´ªå³°ï¼š{max_inq} mÂ³/s")
                        if max_outq is not None:
                            lines.append(f"- å‡ºåº“æ´ªå³°ï¼š{max_outq} mÂ³/s")

            # å¤„ç†ç«™ç‚¹ç»“æœ
            station_result = data.get('station_result', data.get('stations', []))
            if station_result:
                if isinstance(station_result, list):
                    for sta in station_result:
                        sta_name = sta.get('name', 'æœªçŸ¥ç«™ç‚¹')
                        lines.append(f"\nğŸ“ **{sta_name}ï¼š**")
                        peak_flow = sta.get('peak_flow') or sta.get('æ´ªå³°æµé‡')
                        peak_level = sta.get('peak_level') or sta.get('æ´ªå³°æ°´ä½')
                        if peak_flow is not None:
                            lines.append(f"- æ´ªå³°æµé‡ï¼š{peak_flow} mÂ³/s")
                        if peak_level is not None:
                            lines.append(f"- æ´ªå³°æ°´ä½ï¼š{peak_level} m")

        lines.append("\nğŸ’¡ *è¯¦ç»†ä¿¡æ¯å’Œè¿‡ç¨‹æ›²çº¿è¯·æŸ¥çœ‹å·¦ä¾§æŠ¥å‘Šé¡µé¢ã€‚*")

        return "\n".join(lines)

    def _format_single_target_response(
        self,
        target_name: str,
        target_type: str,
        data: Dict[str, Any]
    ) -> List[str]:
        """
        æ ¼å¼åŒ–å•ä¸ªå¯¹è±¡çš„é¢„æŠ¥ç»“æœ

        Args:
            target_name: ç›®æ ‡åç§°
            target_type: ç›®æ ‡ç±»å‹
            data: é¢„æŠ¥æ•°æ®

        Returns:
            æ ¼å¼åŒ–çš„æ–‡å­—è¡Œåˆ—è¡¨
        """
        lines = []

        if target_type == 'reservoir':
            lines.append(f"\nğŸï¸ **{target_name}ï¼š**")
            # å…¥åº“æµé‡ä¿¡æ¯
            inflow_peak = data.get('Max_InQ') or data.get('inflow_peak')
            inflow_peak_time = data.get('MaxInQ_Time') or data.get('inflow_peak_time')
            if inflow_peak is not None:
                lines.append(f"- å…¥åº“æ´ªå³°æµé‡ï¼š{inflow_peak} mÂ³/s")
                if inflow_peak_time:
                    lines.append(f"- å…¥åº“æ´ªå³°æ—¶é—´ï¼š{inflow_peak_time}")
            # å‡ºåº“æµé‡ä¿¡æ¯
            outflow_peak = data.get('Max_OutQ') or data.get('outflow_peak')
            if outflow_peak is not None:
                lines.append(f"- å‡ºåº“æ´ªå³°æµé‡ï¼š{outflow_peak} mÂ³/s")
            # æ°´ä½ä¿¡æ¯
            max_level = data.get('Max_Level') or data.get('max_water_level')
            max_level_time = data.get('MaxLevel_Time')
            if max_level is not None:
                lines.append(f"- æœ€é«˜æ°´ä½ï¼š{max_level} m")
                if max_level_time:
                    lines.append(f"- æœ€é«˜æ°´ä½æ—¶é—´ï¼š{max_level_time}")

        elif target_type == 'station':
            lines.append(f"\nğŸ“ **{target_name}ï¼š**")
            # ç«™ç‚¹é¢„æŠ¥ç»“æœ
            peak_flow = data.get('Max_Qischarge') or data.get('peak_flow')
            peak_time = data.get('MaxQ_AtTime') or data.get('peak_time')
            peak_level = data.get('Max_Level') or data.get('peak_level')
            total_flood = data.get('Total_Flood')
            if peak_flow is not None:
                lines.append(f"- æ´ªå³°æµé‡ï¼š{peak_flow} mÂ³/s")
            if peak_time:
                lines.append(f"- æ´ªå³°åˆ°è¾¾æ—¶é—´ï¼š{peak_time}")
            if peak_level is not None:
                lines.append(f"- æœ€é«˜æ°´ä½ï¼š{peak_level} m")
            if total_flood is not None:
                lines.append(f"- æ€»è¿‡æ´ªé‡ï¼š{total_flood} ä¸‡mÂ³")

        elif target_type == 'detention_basin':
            lines.append(f"\nğŸŒŠ **{target_name}ï¼š**")
            # è“„æ»æ´ªåŒºé¢„æŠ¥ç»“æœ
            state_val = data.get('Xzhq_State') or data.get('çŠ¶æ€')
            if state_val:
                lines.append(f"- çŠ¶æ€ï¼š{state_val}")
            max_inflow = data.get('Max_InQ')
            if max_inflow is not None:
                lines.append(f"- æœ€å¤§è¿›æ´ªæµé‡ï¼š{max_inflow} mÂ³/s")
            total_inflow = data.get('Total_InVolumn')
            if total_inflow is not None:
                lines.append(f"- æ€»è¿›æ´ªé‡ï¼š{total_inflow} ä¸‡mÂ³")

        elif target_type == 'gate':
            lines.append(f"\nğŸš§ **{target_name}ï¼š**")
            # é—¸ç«™é¢„æŠ¥ç»“æœï¼ˆç±»ä¼¼ç«™ç‚¹ï¼‰
            peak_flow = data.get('Max_Qischarge') or data.get('peak_flow')
            peak_level = data.get('Max_Level') or data.get('peak_level')
            if peak_flow is not None:
                lines.append(f"- æ´ªå³°æµé‡ï¼š{peak_flow} mÂ³/s")
            if peak_level is not None:
                lines.append(f"- æœ€é«˜æ°´ä½ï¼š{peak_level} m")

        else:
            lines.append(f"\nğŸ“Š **{target_name}ï¼š**")
            # é€šç”¨æ ¼å¼åŒ–
            for key, value in data.items():
                if not isinstance(value, (dict, list)) and key not in ['message']:
                    lines.append(f"- {key}ï¼š{value}")

        return lines

    async def handle_error_response(self, state: AgentState) -> Dict[str, Any]:
        """
        å¤„ç†é”™è¯¯æƒ…å†µçš„å“åº”
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            é”™è¯¯å“åº”
        """
        error = state.get('error', 'æœªçŸ¥é”™è¯¯')
        user_message = state.get('user_message', '')
        
        logger.warning(f"ç”Ÿæˆé”™è¯¯å“åº”: {error}")
        
        # æ ¹æ®é”™è¯¯ç±»å‹ç”Ÿæˆå‹å¥½çš„å“åº”
        error_responses = {
            "æ„å›¾åˆ†æå¤±è´¥": "æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½ç†è§£æ‚¨çš„é—®é¢˜ï¼Œè¯·å°è¯•ç”¨æ›´æ¸…æ™°çš„æ–¹å¼æè¿°æ‚¨çš„éœ€æ±‚ã€‚",
            "å·¥å…·æ‰§è¡Œå¤±è´¥": "æŠ±æ­‰ï¼Œåœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚",
            "è¶…æ—¶": "æŠ±æ­‰ï¼Œè¯·æ±‚å¤„ç†è¶…æ—¶ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ•°æ®é‡è¾ƒå¤§æˆ–ç½‘ç»œé—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
        }
        
        # åŒ¹é…é”™è¯¯ç±»å‹
        response = None
        for key, msg in error_responses.items():
            if key in error:
                response = msg
                break
        
        if not response:
            response = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚é”™è¯¯ä¿¡æ¯: {error}"
        
        return {
            "output_type": OutputType.TEXT.value,
            "final_response": response,
            "next_action": "end"
        }
    
    async def format_streaming_response(
        self, 
        state: AgentState
    ) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–æµå¼å“åº”æ•°æ®
        
        ç”¨äºWebSocketæˆ–SSEå®æ—¶æ¨é€
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æµå¼å“åº”æ•°æ®
        """
        return {
            "type": "progress",
            "data": {
                "current_step": state.get('current_step_index', 0),
                "total_steps": len(state.get('plan', [])),
                "status": state.get('next_action', 'processing'),
                "message": self._get_progress_message(state)
            }
        }
    
    def _get_progress_message(self, state: AgentState) -> str:
        """è·å–è¿›åº¦æ¶ˆæ¯"""
        action = state.get('next_action', '')
        
        if action == 'plan':
            return "æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜..."
        elif action == 'execute':
            step_index = state.get('current_step_index', 0)
            plan = state.get('plan', [])
            if step_index < len(plan):
                return f"æ­£åœ¨æ‰§è¡Œ: {plan[step_index].get('description', 'å¤„ç†ä¸­...')}"
            return "æ­£åœ¨æ‰§è¡Œä»»åŠ¡..."
        elif action == 'respond':
            return "æ­£åœ¨ç”Ÿæˆå›å¤..."
        elif action == 'wait_async':
            return "æ­£åœ¨ç­‰å¾…åå°ä»»åŠ¡å®Œæˆ..."
        elif action == 'end':
            return "å¤„ç†å®Œæˆ"
        
        return "å¤„ç†ä¸­..."
    
    def _format_execution_results(self, results: List[Dict[str, Any]], plan: List[Dict[str, Any]] = None) -> str:
        """
        æ ¼å¼åŒ–æ‰§è¡Œç»“æœï¼Œè¿‡æ»¤å†…éƒ¨å·¥å…·å’Œæ•æ„Ÿä¿¡æ¯

        å…¼å®¹ä¸¤ç§æ‰§è¡Œæ¨¡å¼ï¼š
        - æ‰¹é‡æ‰§è¡Œæ¨¡å¼ï¼šç»“æœå­—æ®µä¸º 'output'
        - å•æ­¥æ‰§è¡Œæ¨¡å¼ï¼šç»“æœå­—æ®µä¸º 'result'
        """
        if not results:
            return ""

        # æ„å»º step_id -> tool_name æ˜ å°„
        tool_map = {}
        if plan:
            for step in plan:
                tool_map[step.get('step_id')] = step.get('tool_name', '')

        formatted = []
        for r in results:
            step_id = r.get('step_id', '?')
            tool_name = tool_map.get(step_id, '') or r.get('tool_name', '')

            # è¿‡æ»¤ï¼šè·³è¿‡å†…éƒ¨å·¥å…·çš„ç»“æœ
            if tool_name in EXCLUDE_TOOLS_FROM_RESPONSE:
                logger.debug(f"è¿‡æ»¤æ­¥éª¤{step_id}çš„ç»“æœï¼ˆå·¥å…·: {tool_name}ï¼‰")
                continue

            success = r.get('success', False)
            # å…¼å®¹ä¸¤ç§å­—æ®µåï¼š'output'ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰å’Œ 'result'ï¼ˆå•æ­¥æ¨¡å¼ï¼‰
            output = r.get('output') or r.get('result') or r.get('data', '')
            error = r.get('error')

            if success:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è½»é‡åŒ–å¤„ç†
                # å¯¹äºæ‰€æœ‰åŒ…å«å¤§é‡æ—¶åºæ•°æ®çš„ç»“æœéƒ½è¿›è¡Œè½»é‡åŒ–å¤„ç†
                need_lightweight = tool_name in LIGHTWEIGHT_TOOLS

                # æ ¼å¼åŒ–è¾“å‡º
                if isinstance(output, dict):
                    # è¿‡æ»¤æ•æ„Ÿå­—æ®µ
                    filtered_output = self._filter_sensitive_fields(output)
                    # å¯¹æ‰€æœ‰å­—å…¸ç±»å‹çš„è¾“å‡ºè¿›è¡Œè½»é‡åŒ–å¤„ç†ï¼ˆä¸ä»…ä»…æ˜¯ç‰¹å®šå·¥å…·ï¼‰
                    # è¿™æ ·å¯ä»¥é¿å…å¤§é‡æ—¶åºæ•°æ®å¯¼è‡´çš„æ€§èƒ½é—®é¢˜
                    filtered_output = self._lightweight_timeseries_data(filtered_output)
                    output_str = self._format_dict_output(filtered_output)
                elif isinstance(output, list):
                    output_str = self._format_list_output(output)
                elif output:
                    output_str = str(output)
                else:
                    # å¦‚æœæ²¡æœ‰è¾“å‡ºå†…å®¹ï¼Œæ˜¾ç¤ºæ­¥éª¤åç§°
                    step_name = r.get('step_name', '')
                    output_str = f"å®Œæˆ - {step_name}" if step_name else "å®Œæˆ"
                formatted.append(f"æ­¥éª¤{step_id}: {output_str}")
            else:
                formatted.append(f"æ­¥éª¤{step_id}: æ‰§è¡Œå¤±è´¥ - {error}")

        return "\n\n".join(formatted)

    def _lightweight_timeseries_data(self, data: Dict[str, Any], max_timeseries_items: int = 3) -> Dict[str, Any]:
        """
        è½»é‡åŒ–å¤„ç†æ—¶åºæ•°æ®å­—å…¸

        å¯¹äºåŒ…å«å¤§é‡æ—¶åºæ•°æ®çš„å­—å…¸ï¼ˆå¦‚ {'2026-01-21 08:00': 100, '2026-01-21 09:00': 150, ...}ï¼‰ï¼Œ
        åªä¿ç•™å‰å‡ ä¸ªå€¼ä½œä¸ºç¤ºä¾‹ï¼Œé¿å…ä¼ é€’ç»™LLMçš„æ•°æ®è¿‡å¤§ã€‚

        Args:
            data: åŸå§‹æ•°æ®å­—å…¸
            max_timeseries_items: æ—¶åºæ•°æ®æœ€å¤šä¿ç•™çš„é¡¹æ•°

        Returns:
            è½»é‡åŒ–å¤„ç†åçš„å­—å…¸
        """
        if not isinstance(data, dict):
            return data

        result = {}
        for key, value in data.items():
            if isinstance(value, dict):
                # æ£€æŸ¥æ˜¯å¦ä¸ºæ—¶åºæ•°æ®å­—å…¸ï¼ˆé”®çœ‹èµ·æ¥åƒæ—¶é—´æˆ³æˆ–æ—¥æœŸï¼‰
                if self._is_timeseries_dict(value):
                    # æˆªå–å‰å‡ ä¸ªå€¼
                    items = list(value.items())
                    if len(items) > max_timeseries_items:
                        truncated = dict(items[:max_timeseries_items])
                        truncated['...'] = f"(å…±{len(items)}æ¡æ—¶åºæ•°æ®ï¼Œå·²æˆªå–å‰{max_timeseries_items}æ¡)"
                        result[key] = truncated
                    else:
                        result[key] = value
                else:
                    # é€’å½’å¤„ç†åµŒå¥—å­—å…¸
                    result[key] = self._lightweight_timeseries_data(value, max_timeseries_items)
            elif isinstance(value, list) and len(value) > 20:
                # å¯¹äºè¿‡é•¿çš„åˆ—è¡¨ï¼Œä¹Ÿè¿›è¡Œæˆªå–
                result[key] = value[:5] + [f"...(å…±{len(value)}é¡¹)"]
            else:
                result[key] = value

        return result

    def _is_timeseries_dict(self, data: Dict[str, Any]) -> bool:
        """
        åˆ¤æ–­å­—å…¸æ˜¯å¦ä¸ºæ—¶åºæ•°æ®å­—å…¸

        æ—¶åºæ•°æ®å­—å…¸çš„ç‰¹å¾ï¼š
        - é”®æ˜¯æ—¶é—´æ ¼å¼çš„å­—ç¬¦ä¸²ï¼ˆå¦‚ '2026-01-21 08:00:00'ï¼‰
        - å€¼æ˜¯æ•°å€¼ç±»å‹
        """
        if not data or len(data) < 5:
            return False

        # æ£€æŸ¥å‰å‡ ä¸ªé”®æ˜¯å¦ç¬¦åˆæ—¶é—´æ ¼å¼
        sample_keys = list(data.keys())[:3]
        time_pattern_count = 0

        for key in sample_keys:
            if isinstance(key, str):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¥æœŸæ—¶é—´ç‰¹å¾
                if any(sep in key for sep in ['-', '/', ':']) and any(c.isdigit() for c in key):
                    time_pattern_count += 1

        # å¦‚æœå¤§éƒ¨åˆ†é”®ç¬¦åˆæ—¶é—´æ ¼å¼ï¼Œè®¤ä¸ºæ˜¯æ—¶åºæ•°æ®
        return time_pattern_count >= 2

    def _filter_sensitive_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è¿‡æ»¤å­—å…¸ä¸­çš„æ•æ„Ÿå­—æ®µ"""
        filtered = {}
        for key, value in data.items():
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ•æ„Ÿå­—æ®µ
            if any(sensitive in key.lower() for sensitive in SENSITIVE_FIELDS):
                continue
            # é€’å½’å¤„ç†åµŒå¥—å­—å…¸
            if isinstance(value, dict):
                filtered[key] = self._filter_sensitive_fields(value)
            else:
                filtered[key] = value
        return filtered
    
    def _format_dict_output(self, data: Dict[str, Any], max_items: int = 20) -> str:
        """æ ¼å¼åŒ–å­—å…¸è¾“å‡º"""
        items = list(data.items())[:max_items]
        lines = [f"  - {k}: {v}" for k, v in items]
        if len(data) > max_items:
            lines.append(f"  ... å…±{len(data)}é¡¹")
        return "\n".join(lines)

    def _format_list_output(self, data: List[Any], max_items: int = 10) -> str:
        """æ ¼å¼åŒ–åˆ—è¡¨è¾“å‡º"""
        items = data[:max_items]
        lines = [f"  {i+1}. {item}" for i, item in enumerate(items)]
        if len(data) > max_items:
            lines.append(f"  ... å…±{len(data)}é¡¹")
        return "\n".join(lines)
    
    def _format_plan_summary(self, plan: List[Dict[str, Any]], execution_results: List[Dict[str, Any]] = None) -> str:
        """
        æ ¼å¼åŒ–è®¡åˆ’æ‘˜è¦

        Args:
            plan: æ‰§è¡Œè®¡åˆ’æ­¥éª¤åˆ—è¡¨
            execution_results: æ‰§è¡Œç»“æœåˆ—è¡¨ï¼ˆç”¨äºæ¨æ–­æ­¥éª¤çŠ¶æ€ï¼‰

        Returns:
            æ ¼å¼åŒ–çš„è®¡åˆ’æ‘˜è¦å­—ç¬¦ä¸²
        """
        if not plan:
            return ""

        # æ„å»º step_id -> æ‰§è¡Œç»“æœ çš„æ˜ å°„
        result_map = {}
        if execution_results:
            for r in execution_results:
                step_id = r.get('step_id')
                if step_id is not None:
                    result_map[step_id] = r

        steps = []
        for step in plan:
            step_id = step.get('step_id', '?')
            description = step.get('description', '') or step.get('name', '')

            # ä¼˜å…ˆä½¿ç”¨æ­¥éª¤è‡ªå¸¦çš„çŠ¶æ€ï¼Œå¦åˆ™ä»æ‰§è¡Œç»“æœæ¨æ–­
            status = step.get('status')
            if not status and step_id in result_map:
                result = result_map[step_id]
                if result.get('success'):
                    status = 'completed'
                else:
                    status = 'failed'
            elif not status:
                status = 'pending'

            steps.append(f"{step_id}. {description} [{status}]")

        return "\n".join(steps)

    def _format_chat_history(self, chat_history: List[Dict[str, str]], max_turns: int = 2) -> str:
        """æ ¼å¼åŒ–èŠå¤©å†å²ï¼Œé™åˆ¶æœ€è¿‘Nè½®å¯¹è¯"""
        if not chat_history:
            return ""

        # æœ€è¿‘Nè½®å¯¹è¯ï¼ˆæ¯è½®åŒ…å«userå’Œassistantå„ä¸€æ¡ï¼‰
        recent = chat_history[-max_turns * 2:]
        formatted = []
        for msg in recent:
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')
            # é™åˆ¶æ¯æ¡æ¶ˆæ¯é•¿åº¦ï¼Œé¿å…è¿‡é•¿
            if len(content) > 200:
                content = content[:200] + "..."
            formatted.append(f"{role}: {content}")

        return "\n".join(formatted)
    
    def _format_documents(self, documents: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æ–‡æ¡£æ‘˜è¦ï¼ŒåŒ…å«æ¥æºä¿¡æ¯ä¾›LLMå¼•ç”¨"""
        if not documents:
            return ""

        formatted = []
        for i, doc in enumerate(documents[:5], 1):
            # ä¸æˆªæ–­å†…å®¹ï¼Œä¿ç•™å®Œæ•´çš„çŸ¥è¯†åº“æ£€ç´¢ç»“æœ
            content = doc.get('content', '')
            metadata = doc.get('metadata', {})

            # è·å–æ¥æºä¿¡æ¯
            source_url = metadata.get('source', '')  # ç½‘ç»œæœç´¢URL
            doc_name = metadata.get('doc_name', '')  # çŸ¥è¯†åº“æ–‡æ¡£å
            category = metadata.get('category', '')  # çŸ¥è¯†åº“ç±»åˆ«
            title = metadata.get('title', '')

            # æ„å»ºæ¥æºæ ‡è¯†
            if source_url and source_url.startswith('http'):
                # ç½‘ç»œæœç´¢ç»“æœ
                source_label = f"ç½‘ç»œæ¥æº: {title or source_url}"
                source_ref = f"[{title or 'ç½‘ç»œé“¾æ¥'}]({source_url})"
            else:
                # çŸ¥è¯†åº“æ–‡æ¡£ - ç”Ÿæˆå®Œæ•´URL
                kb_id = category or 'unknown'
                display_name = doc_name or kb_id
                source_label = f"çŸ¥è¯†åº“: {kb_id}, æ–‡æ¡£: {doc_name}"
                if doc_name:
                    # ä½¿ç”¨å®Œæ•´URLç¡®ä¿é“¾æ¥æ­£ç¡®
                    source_ref = f"[{display_name}](http://localhost:8000/knowledge/kb-doc/{kb_id}/{doc_name})"
                else:
                    source_ref = f"çŸ¥è¯†åº“-{kb_id}"

            formatted.append(f"[{i}] æ¥æº: {source_label}\næ¥æºå¼•ç”¨æ ¼å¼: {source_ref}\nå†…å®¹: {content}")

        return "\n\n".join(formatted)


# åˆ›å»ºå…¨å±€Controllerå®ä¾‹
_controller_instance: Optional[Controller] = None


def get_controller() -> Controller:
    """è·å–Controllerå•ä¾‹"""
    global _controller_instance
    if _controller_instance is None:
        _controller_instance = Controller()
    return _controller_instance


async def controller_node(state: AgentState) -> Dict[str, Any]:
    """
    LangGraphèŠ‚ç‚¹å‡½æ•° - æ§åˆ¶èŠ‚ç‚¹
    
    åˆæˆæœ€ç»ˆå“åº”
    """
    controller = get_controller()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯éœ€è¦å¤„ç†
    if state.get('error') and not state.get('execution_results'):
        return await controller.handle_error_response(state)
    
    # åˆæˆå“åº”
    return await controller.synthesize_response(state)
