"""
Controller - ç»“æœåˆæˆæ§åˆ¶å™¨
è´Ÿè´£æ•´åˆæ‰§è¡Œç»“æœã€ç”Ÿæˆæœ€ç»ˆå“åº”ã€å¤„ç†è¾“å‡ºæ ¼å¼åŒ–
"""

from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from ..config.settings import settings
from ..config.logging_config import get_logger
from ..config.llm_prompt_logger import log_llm_call
from .state import AgentState, OutputType

logger = get_logger(__name__)


# éœ€è¦è¿‡æ»¤çš„å·¥å…·åˆ—è¡¨ï¼ˆè¿™äº›å·¥å…·çš„ç»“æœä¸ä¼ é€’ç»™å“åº”åˆæˆLLMï¼‰
EXCLUDE_TOOLS_FROM_RESPONSE = [
    "login",           # ç™»å½•å·¥å…·ï¼Œè¿”å›tokenç­‰æ•æ„Ÿä¿¡æ¯
    "get_auth_token",  # è®¤è¯å·¥å…·
]

# éœ€è¦è¿‡æ»¤çš„æ•æ„Ÿå­—æ®µ
SENSITIVE_FIELDS = ["token", "password", "api_key", "secret"]


# å“åº”ç”Ÿæˆæç¤ºè¯
RESPONSE_GENERATION_PROMPT = """ä½ æ˜¯å«å…±æµåŸŸæ•°å­—å­ªç”Ÿç³»ç»Ÿçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè´Ÿè´£ç”Ÿæˆæœ€ç»ˆå“åº”ã€‚

## æœ€è¿‘å¯¹è¯å†å²
{chat_history}

## ç”¨æˆ·åŸå§‹é—®é¢˜
{user_message}

## ç”¨æˆ·æ„å›¾
{intent}

## æ‰§è¡Œè®¡åˆ’
{plan_summary}

## æ‰§è¡Œç»“æœ
{execution_results}

## æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†
{retrieved_documents}

## è¾“å‡ºè¦æ±‚
1. ç»“åˆå¯¹è¯å†å²ç†è§£ç”¨æˆ·é—®é¢˜çš„å®Œæ•´å«ä¹‰ï¼ˆå¦‚ç”¨æˆ·è¯´"å°å—æµ·å‘¢ï¼Ÿ"ï¼Œéœ€ç»“åˆå†å²çŸ¥é“æ˜¯åœ¨é—®æµåŸŸé¢ç§¯ï¼‰
2. æ ¹æ®æ‰§è¡Œç»“æœï¼Œç”Ÿæˆæ¸…æ™°ã€å‡†ç¡®ã€ä¸“ä¸šçš„å›ç­”
3. å¦‚æœæœ‰æ•°æ®æŸ¥è¯¢ç»“æœï¼Œè¯·æ•´ç†æˆæ˜“äºç†è§£çš„æ ¼å¼
4. å¦‚æœæ‰§è¡Œè¿‡ç¨‹ä¸­æœ‰é”™è¯¯ï¼Œè¯·é€‚å½“è¯´æ˜å¹¶ç»™å‡ºå»ºè®®
5. å›ç­”åº”è¯¥ç®€æ´æ˜äº†ï¼Œç›´æ¥åˆ‡ä¸­ä¸»é¢˜ã€‚
6. ã€é‡è¦ã€‘å¦‚æœä½¿ç”¨äº†æ£€ç´¢åˆ°çš„çŸ¥è¯†ï¼Œå¿…é¡»åœ¨å›ç­”æœ«å°¾æ·»åŠ "å‚è€ƒæ¥æº"éƒ¨åˆ†ã€‚ç›´æ¥å¤åˆ¶ä¸Šé¢æ¯æ¡çŸ¥è¯†çš„"æ¥æºå¼•ç”¨æ ¼å¼"å­—æ®µå†…å®¹ä½œä¸ºæ¥æºé“¾æ¥ï¼Œä¸è¦ä¿®æ”¹æˆ–ç®€åŒ–ï¼

è¯·ç”Ÿæˆæœ€ç»ˆå›ç­”:
"""

# Webé¡µé¢ç”Ÿæˆå†³ç­–æç¤ºè¯
WEB_PAGE_DECISION_PROMPT = """æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œå†³å®šæ˜¯å¦éœ€è¦ç”ŸæˆWebé¡µé¢å±•ç¤ºç»“æœã€‚

## ç”¨æˆ·é—®é¢˜
{user_message}

## æ‰§è¡Œç»“æœ
{execution_results}

## åˆ¤æ–­æ ‡å‡†
éœ€è¦ç”ŸæˆWebé¡µé¢çš„æƒ…å†µ:
1. æŸ¥è¯¢ç»“æœåŒ…å«æ—¶åºæ•°æ®ï¼ˆå¦‚æ°´ä½ã€é›¨é‡ã€æµé‡å˜åŒ–ï¼‰
2. éœ€è¦å±•ç¤ºå›¾è¡¨ï¼ˆè¶‹åŠ¿å›¾ã€æŸ±çŠ¶å›¾ã€é¥¼å›¾ç­‰ï¼‰
3. æ•°æ®é‡è¾ƒå¤§ï¼Œéœ€è¦è¡¨æ ¼å±•ç¤º
4. åŒ…å«åœ°ç†ä¿¡æ¯éœ€è¦åœ°å›¾å±•ç¤º

ä¸éœ€è¦Webé¡µé¢çš„æƒ…å†µ:
1. ç®€å•çš„æ–‡å­—å›ç­”
2. å•ä¸ªæ•°å€¼æŸ¥è¯¢
3. çŸ¥è¯†é—®ç­”ç±»é—®é¢˜

è¯·è¿”å›JSONæ ¼å¼:
{{
    "need_web_page": true/false,
    "page_type": "chart/table/map/dashboard/none",
    "reason": "åˆ¤æ–­ç†ç”±"
}}
"""


class Controller:
    """ç»“æœåˆæˆæ§åˆ¶å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ§åˆ¶å™¨"""
        # æ€è€ƒæ¨¡å¼é…ç½®ï¼ˆç”¨äºQwen3ç­‰æ¨¡å‹ï¼Œéæµå¼è°ƒç”¨éœ€è®¾ç½®ä¸ºfalseï¼‰
        extra_body = {"enable_thinking": settings.llm_enable_thinking}

        # ç»“æœåˆæˆLLM
        synthesis_cfg = settings.get_synthesis_config()
        self.llm = ChatOpenAI(
            api_key=synthesis_cfg["api_key"],
            base_url=synthesis_cfg["api_base"],
            model=synthesis_cfg["model"],
            temperature=synthesis_cfg["temperature"],
            model_kwargs={"extra_body": extra_body}
        )

        # å“åº”ç”Ÿæˆé“¾
        self.response_prompt = ChatPromptTemplate.from_template(RESPONSE_GENERATION_PROMPT)
        self.response_chain = self.response_prompt | self.llm

        logger.info("Controlleråˆå§‹åŒ–å®Œæˆ")
    
    async def synthesize_response(self, state: AgentState) -> Dict[str, Any]:
        """
        åˆæˆæœ€ç»ˆå“åº”

        Args:
            state: å½“å‰æ™ºèƒ½ä½“çŠ¶æ€

        Returns:
            åŒ…å«æœ€ç»ˆå“åº”çš„çŠ¶æ€æ›´æ–°
        """
        logger.info("å¼€å§‹åˆæˆæœ€ç»ˆå“åº”...")

        try:
            # æ ¼å¼åŒ–æ‰§è¡Œç»“æœï¼ˆä¼ å…¥planç”¨äºè¿‡æ»¤å†…éƒ¨å·¥å…·ï¼‰
            execution_summary = self._format_execution_results(
                state.get('execution_results', []),
                state.get('plan', [])
            )

            # æ ¼å¼åŒ–è®¡åˆ’æ‘˜è¦
            plan_summary = self._format_plan_summary(state.get('plan', []))

            # æ ¼å¼åŒ–æ£€ç´¢æ–‡æ¡£
            docs_summary = self._format_documents(
                state.get('retrieved_documents', [])
            )

            # æ ¼å¼åŒ–èŠå¤©å†å²ï¼ˆé™åˆ¶æœ€è¿‘2è½®å¯¹è¯ï¼‰
            chat_history_str = self._format_chat_history(state.get('chat_history', []))

            # æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å·²ç»ç”Ÿæˆäº†é¡µé¢URL
            workflow_page_url = state.get('generated_page_url')
            if workflow_page_url:
                logger.info(f"å·¥ä½œæµå·²ç”Ÿæˆé¡µé¢URL: {workflow_page_url}")
                # ç”Ÿæˆæ–‡å­—å›å¤
                text_response = await self._generate_text_response_for_workflow(state, execution_summary)
                return {
                    "output_type": OutputType.WEB_PAGE.value,
                    "final_response": text_response,
                    "generated_page_url": workflow_page_url,
                    "page_generating": False,
                    "next_action": "end"
                }

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”ŸæˆWebé¡µé¢
            output_type = state.get('output_type', 'text')

            if output_type == OutputType.WEB_PAGE.value or await self._should_generate_web_page(state):
                # éœ€è¦ç”ŸæˆWebé¡µé¢ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰
                response = await self._generate_web_page_response(state, execution_summary)
                return {
                    "output_type": OutputType.WEB_PAGE.value,
                    "final_response": response['text_response'],
                    "generated_page_url": response.get('page_url'),
                    "page_task_id": response.get('page_task_id'),
                    "page_generating": response.get('page_generating', False),
                    "next_action": "end"
                }

            # å‡†å¤‡ä¸Šä¸‹æ–‡å˜é‡
            context_vars = {
                "chat_history": chat_history_str or "æ— ",
                "user_message": state.get('user_message', ''),
                "intent": state.get('intent', 'unknown'),
                "plan_summary": plan_summary or "æ— æ‰§è¡Œè®¡åˆ’",
                "execution_results": execution_summary or "æ— æ‰§è¡Œç»“æœ",
                "retrieved_documents": docs_summary or "æ— ç›¸å…³çŸ¥è¯†"
            }

            # ç”Ÿæˆæ–‡æœ¬å“åº”
            import time
            _start = time.time()
            response = await self.response_chain.ainvoke(context_vars)
            _elapsed = time.time() - _start

            # è®°å½•LLMè°ƒç”¨æ—¥å¿—
            full_prompt = RESPONSE_GENERATION_PROMPT.format(**context_vars)
            log_llm_call(
                step_name="å“åº”åˆæˆ",
                module_name="Controller.synthesize_response",
                prompt_template_name="RESPONSE_GENERATION_PROMPT",
                context_variables=context_vars,
                full_prompt=full_prompt,
                response=response.content,
                elapsed_time=_elapsed
            )

            logger.info("å“åº”åˆæˆå®Œæˆ")

            return {
                "output_type": OutputType.TEXT.value,
                "final_response": response.content,
                "next_action": "end"
            }

        except Exception as e:
            logger.error(f"å“åº”åˆæˆå¤±è´¥: {e}")
            return {
                "output_type": OutputType.TEXT.value,
                "final_response": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜: {str(e)}",
                "error": str(e),
                "next_action": "end"
            }
    
    async def _should_generate_web_page(self, state: AgentState) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦ç”ŸæˆWebé¡µé¢
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æ˜¯å¦éœ€è¦ç”ŸæˆWebé¡µé¢
        """
        execution_results = state.get('execution_results', [])
        
        # å¿«é€Ÿåˆ¤æ–­ï¼šå¦‚æœç»“æœä¸­åŒ…å«å¤§é‡æ•°æ®ï¼Œå¯èƒ½éœ€è¦Webé¡µé¢
        for result in execution_results:
            output = result.get('output')
            if isinstance(output, (list, dict)):
                # å¦‚æœæ˜¯åˆ—è¡¨ä¸”é•¿åº¦è¶…è¿‡10ï¼Œæˆ–åŒ…å«æ—¶åºæ•°æ®å…³é”®å­—
                if isinstance(output, list) and len(output) > 10:
                    return True
                if isinstance(output, dict):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾è¡¨ç›¸å…³çš„æ•°æ®ç»“æ„
                    if any(key in output for key in ['data', 'series', 'values', 'time_series']):
                        return True
        
        return False
    
    async def _generate_web_page_response(
        self,
        state: AgentState,
        execution_summary: str
    ) -> Dict[str, Any]:
        """
        ç”ŸæˆWebé¡µé¢å“åº”ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰

        é¡µé¢ç”Ÿæˆç”±ç‹¬ç«‹çš„å¼‚æ­¥æ™ºèƒ½ä½“æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»å¯¹è¯æµç¨‹ã€‚
        è¿”å›ä»»åŠ¡IDï¼Œå‰ç«¯é€šè¿‡è½®è¯¢æˆ–WebSocketè·å–é¡µé¢URLã€‚

        Args:
            state: å½“å‰çŠ¶æ€
            execution_summary: æ‰§è¡Œç»“æœæ‘˜è¦

        Returns:
            åŒ…å«æ–‡æœ¬å“åº”å’Œé¡µé¢ä»»åŠ¡IDçš„å­—å…¸
        """
        logger.info("å‡†å¤‡å¼‚æ­¥ç”ŸæˆWebé¡µé¢...")

        # å…ˆç”Ÿæˆæ–‡å­—å›å¤ï¼ˆä¸é˜»å¡ï¼‰
        text_response = None
        results = state.get('execution_results', [])

        # æ£€æŸ¥æœ€åä¸€æ­¥æ˜¯å¦å·²ç»æ˜¯LLMç”Ÿæˆçš„æ–‡å­—æ€»ç»“
        if results:
            last_result = results[-1]
            last_output = last_result.get('output')
            if last_result.get('success') and isinstance(last_output, str) and len(last_output) > 20:
                text_response = last_output
                logger.info("å¤ç”¨æ‰§è¡Œæ­¥éª¤ä¸­çš„LLMæ€»ç»“ï¼Œè·³è¿‡é‡å¤ç”Ÿæˆ")

        if not text_response:
            # éœ€è¦LLMç”Ÿæˆæ–‡å­—å›å¤
            docs_summary = self._format_documents(state.get('retrieved_documents', []))
            plan_summary = self._format_plan_summary(state.get('plan', []))

            try:
                chat_history_str = self._format_chat_history(state.get('chat_history', []))
                web_context_vars = {
                    "chat_history": chat_history_str or "æ— ",
                    "user_message": state.get('user_message', ''),
                    "intent": state.get('intent', 'unknown'),
                    "plan_summary": plan_summary or "æ— æ‰§è¡Œè®¡åˆ’",
                    "execution_results": execution_summary or "æ— æ‰§è¡Œç»“æœ",
                    "retrieved_documents": docs_summary or "æ— ç›¸å…³çŸ¥è¯†"
                }

                import time
                _start = time.time()
                llm_response = await self.response_chain.ainvoke(web_context_vars)
                _elapsed = time.time() - _start
                text_response = llm_response.content

                full_prompt = RESPONSE_GENERATION_PROMPT.format(**web_context_vars)
                log_llm_call(
                    step_name="Webé¡µé¢å“åº”åˆæˆ",
                    module_name="Controller._generate_web_page_response",
                    prompt_template_name="RESPONSE_GENERATION_PROMPT",
                    context_variables=web_context_vars,
                    full_prompt=full_prompt,
                    response=text_response,
                    elapsed_time=_elapsed
                )
                logger.info("LLMç”Ÿæˆæ–‡å­—å›å¤æˆåŠŸ")
            except Exception as llm_error:
                logger.warning(f"LLMç”Ÿæˆæ–‡å­—å›å¤å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {llm_error}")
                text_response = f"""æ ¹æ®æ‚¨çš„æŸ¥è¯¢ï¼Œç³»ç»Ÿæ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šã€‚

{execution_summary}

æŠ¥å‘Šç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™..."""

        # å¼‚æ­¥æäº¤é¡µé¢ç”Ÿæˆä»»åŠ¡
        try:
            from ..output.async_page_agent import get_async_page_agent

            # æ•´åˆæ‰€æœ‰æ‰§è¡Œç»“æœæ•°æ®
            combined_data = {}
            for result in results:
                if result.get('success'):
                    output = result.get('output')
                    if isinstance(output, dict):
                        combined_data.update(output)

            # ç¡®å®šæŠ¥å‘Šç±»å‹
            report_type = "generic"
            intent = state.get('intent', '')
            if 'æ´ªæ°´' in intent or 'é¢„æŠ¥' in intent:
                report_type = 'flood_forecast'
            elif 'é¢„æ¡ˆ' in intent:
                report_type = 'emergency_plan'

            # æäº¤å¼‚æ­¥ä»»åŠ¡
            async_agent = get_async_page_agent()
            task_id = async_agent.submit_task(
                conversation_id=state.get('conversation_id', ''),
                report_type=report_type,
                data=combined_data,
                title=f"{intent}æŠ¥å‘Š",
                execution_summary=execution_summary
            )

            logger.info(f"é¡µé¢ç”Ÿæˆä»»åŠ¡å·²æäº¤: {task_id}")

            return {
                "text_response": text_response,
                "page_url": None,  # é¡µé¢URLç¨åé€šè¿‡ä»»åŠ¡çŠ¶æ€è·å–
                "page_task_id": task_id,
                "page_generating": True
            }

        except Exception as e:
            logger.error(f"æäº¤é¡µé¢ç”Ÿæˆä»»åŠ¡å¤±è´¥: {e}")
            return {
                "text_response": text_response,
                "page_url": None,
                "page_task_id": None,
                "page_generating": False,
                "page_error": str(e)
            }

    async def _generate_text_response_for_workflow(
        self,
        state: AgentState,
        execution_summary: str
    ) -> str:
        """
        ä¸ºå·¥ä½œæµç”Ÿæˆæ–‡å­—å›å¤

        å½“å·¥ä½œæµå·²ç»ç”Ÿæˆäº†é¡µé¢URLæ—¶ï¼Œåªéœ€è¦ç”Ÿæˆæ–‡å­—å›å¤ã€‚

        Args:
            state: å½“å‰çŠ¶æ€
            execution_summary: æ‰§è¡Œç»“æœæ‘˜è¦

        Returns:
            æ–‡å­—å›å¤
        """
        # æ£€æŸ¥å·¥ä½œæµç»“æœä¸­æ˜¯å¦æœ‰æå–çš„æ•°æ®
        extracted_result = state.get('extracted_result', {})
        forecast_target = state.get('forecast_target', {})

        logger.info(f"ç”Ÿæˆå·¥ä½œæµæ–‡å­—å›å¤ - extracted_resultå­˜åœ¨: {bool(extracted_result)}, forecast_target: {forecast_target}")

        # å¦‚æœæœ‰æå–çš„ç»“æœï¼ŒåŸºäºç»“æœç”Ÿæˆå›å¤
        if extracted_result:
            target_name = forecast_target.get('name', 'ç›®æ ‡')
            target_type = forecast_target.get('type', 'basin')
            summary = extracted_result.get('summary', '')
            data = extracted_result.get('data', {})

            logger.info(f"æå–ç»“æœ - summary: {summary}, dataå­˜åœ¨: {bool(data)}, dataæœ‰message: {data.get('message') if data else None}")

            # æ„å»ºæ ¼å¼åŒ–çš„æ–‡å­—å›å¤
            if data and not data.get('message'):
                # æœ‰æœ‰æ•ˆæ•°æ®ï¼Œç”Ÿæˆæ ¼å¼åŒ–å›å¤
                result = self._format_forecast_response(target_name, target_type, summary, data)
                logger.info(f"ç”Ÿæˆçš„æ–‡å­—å›å¤: {result[:100]}...")
                return result
            elif data.get('message'):
                # æœ‰é”™è¯¯æ¶ˆæ¯
                return data.get('message')

        # ä½¿ç”¨LLMç”Ÿæˆå›å¤
        logger.info("extracted_resultä¸ºç©ºæˆ–æ— æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨LLMç”Ÿæˆå›å¤")
        try:
            chat_history_str = self._format_chat_history(state.get('chat_history', []))
            docs_summary = self._format_documents(state.get('retrieved_documents', []))

            context_vars = {
                "chat_history": chat_history_str or "æ— ",
                "user_message": state.get('user_message', ''),
                "intent": state.get('intent', 'unknown'),
                "plan_summary": "å·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                "execution_results": execution_summary or "æ— æ‰§è¡Œç»“æœ",
                "retrieved_documents": docs_summary or "æ— ç›¸å…³çŸ¥è¯†"
            }

            import time
            _start = time.time()
            response = await self.response_chain.ainvoke(context_vars)
            _elapsed = time.time() - _start

            full_prompt = RESPONSE_GENERATION_PROMPT.format(**context_vars)
            log_llm_call(
                step_name="å·¥ä½œæµå“åº”åˆæˆ",
                module_name="Controller._generate_text_response_for_workflow",
                prompt_template_name="RESPONSE_GENERATION_PROMPT",
                context_variables=context_vars,
                full_prompt=full_prompt,
                response=response.content,
                elapsed_time=_elapsed
            )

            return response.content

        except Exception as e:
            logger.warning(f"LLMç”Ÿæˆå›å¤å¤±è´¥: {e}")
            return f"å·²å®ŒæˆæŸ¥è¯¢ï¼Œè¯¦ç»†ç»“æœè¯·æŸ¥çœ‹å³ä¾§æŠ¥å‘Šé¡µé¢ã€‚"

    def _format_forecast_response(
        self,
        target_name: str,
        target_type: str,
        summary: str,
        data: Dict[str, Any]
    ) -> str:
        """
        æ ¼å¼åŒ–é¢„æŠ¥ç»“æœä¸ºæ–‡å­—å›å¤

        Args:
            target_name: ç›®æ ‡åç§°ï¼ˆå¦‚æ°´åº“åã€ç«™ç‚¹åï¼‰
            target_type: ç›®æ ‡ç±»å‹ï¼ˆreservoir/station/detention_basin/basin/multipleï¼‰
            summary: æ‘˜è¦ä¿¡æ¯
            data: é¢„æŠ¥æ•°æ®

        Returns:
            æ ¼å¼åŒ–çš„æ–‡å­—å›å¤
        """
        lines = [f"**{summary}**\n"]

        # å¤šå¯¹è±¡æŸ¥è¯¢ç»“æœï¼ˆæ”¯æŒ targets å’Œ results ä¸¤ç§æ ¼å¼ï¼‰
        if target_type == 'multiple':
            items = data.get('targets') or data.get('results') or []
            if items:
                for result_item in items:
                    item_data = result_item.get('data', {})
                    # å…¼å®¹ä¸¤ç§æ ¼å¼ï¼šç›´æ¥çš„ name/type æˆ–åµŒå¥—çš„ target.name/target.type
                    item_name = result_item.get('name') or result_item.get('target', {}).get('name', 'æœªçŸ¥å¯¹è±¡')
                    item_type = result_item.get('type') or result_item.get('target', {}).get('type', 'basin')

                    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯æ¶ˆæ¯
                    if item_data.get('message'):
                        lines.append(f"\nâš ï¸ **{item_name}**ï¼š{item_data.get('message')}")
                        continue

                    # æ ¹æ®ç±»å‹æ ¼å¼åŒ–å•ä¸ªå¯¹è±¡çš„ç»“æœ
                    single_lines = self._format_single_target_response(item_name, item_type, item_data)
                    lines.extend(single_lines)

                lines.append("\nğŸ’¡ *è¯¦ç»†ä¿¡æ¯å’Œè¿‡ç¨‹æ›²çº¿è¯·æŸ¥çœ‹å·¦ä¾§æŠ¥å‘Šé¡µé¢ã€‚*")
                return "\n".join(lines)

        if target_type == 'reservoir':
            # æ°´åº“é¢„æŠ¥ç»“æœæ ¼å¼åŒ–
            lines.append(f"ğŸ“Š **{target_name}é¢„æŠ¥æ•°æ®ï¼š**\n")

            # å…¥åº“æµé‡ä¿¡æ¯
            inflow_peak = data.get('Max_InQ') or data.get('inflow_peak') or data.get('å…¥åº“æ´ªå³°æµé‡')
            inflow_peak_time = data.get('MaxInQ_Time') or data.get('inflow_peak_time') or data.get('å…¥åº“æ´ªå³°æ—¶é—´')
            if inflow_peak is not None:
                lines.append(f"- **å…¥åº“æ´ªå³°æµé‡**ï¼š{inflow_peak} mÂ³/s")
                if inflow_peak_time:
                    lines.append(f"- **å…¥åº“æ´ªå³°æ—¶é—´**ï¼š{inflow_peak_time}")

            # å‡ºåº“æµé‡ä¿¡æ¯
            outflow_peak = data.get('Max_OutQ') or data.get('outflow_peak') or data.get('å‡ºåº“æ´ªå³°æµé‡')
            outflow_peak_time = data.get('MaxOutQ_Time') or data.get('outflow_peak_time') or data.get('å‡ºåº“æ´ªå³°æ—¶é—´')
            if outflow_peak is not None:
                lines.append(f"- **å‡ºåº“æ´ªå³°æµé‡**ï¼š{outflow_peak} mÂ³/s")
                if outflow_peak_time:
                    lines.append(f"- **å‡ºåº“æ´ªå³°æ—¶é—´**ï¼š{outflow_peak_time}")

            # æ°´ä½ä¿¡æ¯
            max_level = data.get('Max_Level') or data.get('max_water_level') or data.get('æœ€é«˜æ°´ä½')
            max_level_time = data.get('MaxLevel_Time') or data.get('max_water_level_time') or data.get('æœ€é«˜æ°´ä½æ—¶é—´')
            if max_level is not None:
                lines.append(f"- **æœ€é«˜æ°´ä½**ï¼š{max_level} m")
                if max_level_time:
                    lines.append(f"- **æœ€é«˜æ°´ä½æ—¶é—´**ï¼š{max_level_time}")

            # è“„æ°´é‡ä¿¡æ¯
            max_storage = data.get('Max_Volumn') or data.get('max_storage') or data.get('æœ€å¤§è“„æ°´é‡')
            if max_storage is not None:
                lines.append(f"- **æœ€å¤§è“„æ°´é‡**ï¼š{max_storage} ä¸‡mÂ³")

            # æ€»å…¥åº“é‡å’Œæ€»å‡ºåº“é‡
            total_inflow = data.get('Total_InVolumn') or data.get('æ€»å…¥åº“é‡')
            total_outflow = data.get('Total_OutVolumn') or data.get('æ€»å‡ºåº“é‡')
            if total_inflow is not None:
                lines.append(f"- **æ€»å…¥åº“é‡**ï¼š{total_inflow} ä¸‡mÂ³")
            if total_outflow is not None:
                lines.append(f"- **æ€»å‡ºåº“é‡**ï¼š{total_outflow} ä¸‡mÂ³")

            # é¢„æŠ¥ç»“æŸæ—¶çŠ¶æ€
            end_level = data.get('EndTime_Level') or data.get('é¢„æŠ¥ç»“æŸæ°´ä½')
            end_storage = data.get('EndTime_Volumn') or data.get('é¢„æŠ¥ç»“æŸè“„æ°´é‡')
            if end_level is not None or end_storage is not None:
                lines.append(f"\nğŸ“ˆ **é¢„æŠ¥ç»“æŸæ—¶çŠ¶æ€ï¼š**")
                if end_level is not None:
                    lines.append(f"- **æ°´ä½**ï¼š{end_level} m")
                if end_storage is not None:
                    lines.append(f"- **è“„æ°´é‡**ï¼š{end_storage} ä¸‡mÂ³")

        elif target_type == 'station':
            # ç«™ç‚¹é¢„æŠ¥ç»“æœæ ¼å¼åŒ–
            lines.append(f"ğŸ“Š **{target_name}é¢„æŠ¥æ•°æ®ï¼š**\n")

            # æ ¹æ®APIè¿”å›çš„å­—æ®µåè·å–æ•°æ®
            # APIå­—æ®µ: Max_Qischarge, MaxQ_AtTime, Max_Level, Total_Flood, Stcd, SectionName
            peak_flow = data.get('Max_Qischarge') or data.get('peak_flow') or data.get('æ´ªå³°æµé‡')
            peak_time = data.get('MaxQ_AtTime') or data.get('peak_time') or data.get('æ´ªå³°æ—¶é—´')
            peak_level = data.get('Max_Level') or data.get('peak_level') or data.get('æ´ªå³°æ°´ä½')
            total_flood = data.get('Total_Flood') or data.get('æ€»è¿‡æ´ªé‡')
            stcd = data.get('Stcd')
            section_name = data.get('SectionName')

            if section_name:
                lines.append(f"- **æ–­é¢åç§°**ï¼š{section_name}")
            if stcd:
                lines.append(f"- **ç«™ç‚¹ç¼–ç **ï¼š{stcd}")
            if peak_flow is not None:
                lines.append(f"- **æ´ªå³°æµé‡**ï¼š{peak_flow} mÂ³/s")
            if peak_time:
                lines.append(f"- **æ´ªå³°åˆ°è¾¾æ—¶é—´**ï¼š{peak_time}")
            if peak_level is not None:
                lines.append(f"- **æœ€é«˜æ°´ä½**ï¼š{peak_level} m")
            if total_flood is not None:
                lines.append(f"- **æ€»è¿‡æ´ªé‡**ï¼š{total_flood} ä¸‡mÂ³")

        elif target_type == 'detention_basin':
            # è“„æ»æ´ªåŒºé¢„æŠ¥ç»“æœæ ¼å¼åŒ–
            lines.append(f"ğŸ“Š **{target_name}é¢„æŠ¥æ•°æ®ï¼š**\n")

            # æ˜¾ç¤ºæ‰€æœ‰éæ—¶åºæ•°æ®å­—æ®µ
            skip_keys = {'message', 'InQ_Dic', 'OutQ_Dic', 'Level_Dic', 'Volumn_Dic',
                        'YHDOutQ_Dic', 'XHDOutQ_Dic'}
            for key, value in data.items():
                if key not in skip_keys and not isinstance(value, dict):
                    lines.append(f"- **{key}**ï¼š{value}")

        else:
            # å…¨æµåŸŸæˆ–å…¶ä»–ç±»å‹
            lines.append(f"ğŸ“Š **é¢„æŠ¥æ•°æ®ï¼š**\n")

            # å¤„ç†æ°´åº“ç»“æœ
            reservoir_result = data.get('reservoir_result', {})
            if reservoir_result:
                for res_name, res_data in reservoir_result.items():
                    lines.append(f"\nğŸï¸ **{res_name}ï¼š**")
                    if isinstance(res_data, dict):
                        max_level = res_data.get('Max_Level')
                        max_inq = res_data.get('Max_InQ')
                        max_outq = res_data.get('Max_OutQ')
                        if max_level is not None:
                            lines.append(f"- æœ€é«˜æ°´ä½ï¼š{max_level} m")
                        if max_inq is not None:
                            lines.append(f"- å…¥åº“æ´ªå³°ï¼š{max_inq} mÂ³/s")
                        if max_outq is not None:
                            lines.append(f"- å‡ºåº“æ´ªå³°ï¼š{max_outq} mÂ³/s")

            # å¤„ç†ç«™ç‚¹ç»“æœ
            station_result = data.get('station_result', data.get('stations', []))
            if station_result:
                if isinstance(station_result, list):
                    for sta in station_result:
                        sta_name = sta.get('name', 'æœªçŸ¥ç«™ç‚¹')
                        lines.append(f"\nğŸ“ **{sta_name}ï¼š**")
                        peak_flow = sta.get('peak_flow') or sta.get('æ´ªå³°æµé‡')
                        peak_level = sta.get('peak_level') or sta.get('æ´ªå³°æ°´ä½')
                        if peak_flow is not None:
                            lines.append(f"- æ´ªå³°æµé‡ï¼š{peak_flow} mÂ³/s")
                        if peak_level is not None:
                            lines.append(f"- æ´ªå³°æ°´ä½ï¼š{peak_level} m")

        lines.append("\nğŸ’¡ *è¯¦ç»†ä¿¡æ¯å’Œè¿‡ç¨‹æ›²çº¿è¯·æŸ¥çœ‹å·¦ä¾§æŠ¥å‘Šé¡µé¢ã€‚*")

        return "\n".join(lines)

    def _format_single_target_response(
        self,
        target_name: str,
        target_type: str,
        data: Dict[str, Any]
    ) -> List[str]:
        """
        æ ¼å¼åŒ–å•ä¸ªå¯¹è±¡çš„é¢„æŠ¥ç»“æœ

        Args:
            target_name: ç›®æ ‡åç§°
            target_type: ç›®æ ‡ç±»å‹
            data: é¢„æŠ¥æ•°æ®

        Returns:
            æ ¼å¼åŒ–çš„æ–‡å­—è¡Œåˆ—è¡¨
        """
        lines = []

        if target_type == 'reservoir':
            lines.append(f"\nğŸï¸ **{target_name}ï¼š**")
            # å…¥åº“æµé‡ä¿¡æ¯
            inflow_peak = data.get('Max_InQ') or data.get('inflow_peak')
            inflow_peak_time = data.get('MaxInQ_Time') or data.get('inflow_peak_time')
            if inflow_peak is not None:
                lines.append(f"- å…¥åº“æ´ªå³°æµé‡ï¼š{inflow_peak} mÂ³/s")
                if inflow_peak_time:
                    lines.append(f"- å…¥åº“æ´ªå³°æ—¶é—´ï¼š{inflow_peak_time}")
            # å‡ºåº“æµé‡ä¿¡æ¯
            outflow_peak = data.get('Max_OutQ') or data.get('outflow_peak')
            if outflow_peak is not None:
                lines.append(f"- å‡ºåº“æ´ªå³°æµé‡ï¼š{outflow_peak} mÂ³/s")
            # æ°´ä½ä¿¡æ¯
            max_level = data.get('Max_Level') or data.get('max_water_level')
            max_level_time = data.get('MaxLevel_Time')
            if max_level is not None:
                lines.append(f"- æœ€é«˜æ°´ä½ï¼š{max_level} m")
                if max_level_time:
                    lines.append(f"- æœ€é«˜æ°´ä½æ—¶é—´ï¼š{max_level_time}")

        elif target_type == 'station':
            lines.append(f"\nğŸ“ **{target_name}ï¼š**")
            # ç«™ç‚¹é¢„æŠ¥ç»“æœ
            peak_flow = data.get('Max_Qischarge') or data.get('peak_flow')
            peak_time = data.get('MaxQ_AtTime') or data.get('peak_time')
            peak_level = data.get('Max_Level') or data.get('peak_level')
            total_flood = data.get('Total_Flood')
            if peak_flow is not None:
                lines.append(f"- æ´ªå³°æµé‡ï¼š{peak_flow} mÂ³/s")
            if peak_time:
                lines.append(f"- æ´ªå³°åˆ°è¾¾æ—¶é—´ï¼š{peak_time}")
            if peak_level is not None:
                lines.append(f"- æœ€é«˜æ°´ä½ï¼š{peak_level} m")
            if total_flood is not None:
                lines.append(f"- æ€»è¿‡æ´ªé‡ï¼š{total_flood} ä¸‡mÂ³")

        elif target_type == 'detention_basin':
            lines.append(f"\nğŸŒŠ **{target_name}ï¼š**")
            # è“„æ»æ´ªåŒºé¢„æŠ¥ç»“æœ
            state_val = data.get('Xzhq_State') or data.get('çŠ¶æ€')
            if state_val:
                lines.append(f"- çŠ¶æ€ï¼š{state_val}")
            max_inflow = data.get('Max_InQ')
            if max_inflow is not None:
                lines.append(f"- æœ€å¤§è¿›æ´ªæµé‡ï¼š{max_inflow} mÂ³/s")
            total_inflow = data.get('Total_InVolumn')
            if total_inflow is not None:
                lines.append(f"- æ€»è¿›æ´ªé‡ï¼š{total_inflow} ä¸‡mÂ³")

        elif target_type == 'gate':
            lines.append(f"\nğŸš§ **{target_name}ï¼š**")
            # é—¸ç«™é¢„æŠ¥ç»“æœï¼ˆç±»ä¼¼ç«™ç‚¹ï¼‰
            peak_flow = data.get('Max_Qischarge') or data.get('peak_flow')
            peak_level = data.get('Max_Level') or data.get('peak_level')
            if peak_flow is not None:
                lines.append(f"- æ´ªå³°æµé‡ï¼š{peak_flow} mÂ³/s")
            if peak_level is not None:
                lines.append(f"- æœ€é«˜æ°´ä½ï¼š{peak_level} m")

        else:
            lines.append(f"\nğŸ“Š **{target_name}ï¼š**")
            # é€šç”¨æ ¼å¼åŒ–
            for key, value in data.items():
                if not isinstance(value, (dict, list)) and key not in ['message']:
                    lines.append(f"- {key}ï¼š{value}")

        return lines

    async def handle_error_response(self, state: AgentState) -> Dict[str, Any]:
        """
        å¤„ç†é”™è¯¯æƒ…å†µçš„å“åº”
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            é”™è¯¯å“åº”
        """
        error = state.get('error', 'æœªçŸ¥é”™è¯¯')
        user_message = state.get('user_message', '')
        
        logger.warning(f"ç”Ÿæˆé”™è¯¯å“åº”: {error}")
        
        # æ ¹æ®é”™è¯¯ç±»å‹ç”Ÿæˆå‹å¥½çš„å“åº”
        error_responses = {
            "æ„å›¾åˆ†æå¤±è´¥": "æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½ç†è§£æ‚¨çš„é—®é¢˜ï¼Œè¯·å°è¯•ç”¨æ›´æ¸…æ™°çš„æ–¹å¼æè¿°æ‚¨çš„éœ€æ±‚ã€‚",
            "å·¥å…·æ‰§è¡Œå¤±è´¥": "æŠ±æ­‰ï¼Œåœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚",
            "è¶…æ—¶": "æŠ±æ­‰ï¼Œè¯·æ±‚å¤„ç†è¶…æ—¶ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ•°æ®é‡è¾ƒå¤§æˆ–ç½‘ç»œé—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
        }
        
        # åŒ¹é…é”™è¯¯ç±»å‹
        response = None
        for key, msg in error_responses.items():
            if key in error:
                response = msg
                break
        
        if not response:
            response = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚é”™è¯¯ä¿¡æ¯: {error}"
        
        return {
            "output_type": OutputType.TEXT.value,
            "final_response": response,
            "next_action": "end"
        }
    
    async def format_streaming_response(
        self, 
        state: AgentState
    ) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–æµå¼å“åº”æ•°æ®
        
        ç”¨äºWebSocketæˆ–SSEå®æ—¶æ¨é€
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            æµå¼å“åº”æ•°æ®
        """
        return {
            "type": "progress",
            "data": {
                "current_step": state.get('current_step_index', 0),
                "total_steps": len(state.get('plan', [])),
                "status": state.get('next_action', 'processing'),
                "message": self._get_progress_message(state)
            }
        }
    
    def _get_progress_message(self, state: AgentState) -> str:
        """è·å–è¿›åº¦æ¶ˆæ¯"""
        action = state.get('next_action', '')
        
        if action == 'plan':
            return "æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜..."
        elif action == 'execute':
            step_index = state.get('current_step_index', 0)
            plan = state.get('plan', [])
            if step_index < len(plan):
                return f"æ­£åœ¨æ‰§è¡Œ: {plan[step_index].get('description', 'å¤„ç†ä¸­...')}"
            return "æ­£åœ¨æ‰§è¡Œä»»åŠ¡..."
        elif action == 'respond':
            return "æ­£åœ¨ç”Ÿæˆå›å¤..."
        elif action == 'wait_async':
            return "æ­£åœ¨ç­‰å¾…åå°ä»»åŠ¡å®Œæˆ..."
        elif action == 'end':
            return "å¤„ç†å®Œæˆ"
        
        return "å¤„ç†ä¸­..."
    
    def _format_execution_results(self, results: List[Dict[str, Any]], plan: List[Dict[str, Any]] = None) -> str:
        """æ ¼å¼åŒ–æ‰§è¡Œç»“æœï¼Œè¿‡æ»¤å†…éƒ¨å·¥å…·å’Œæ•æ„Ÿä¿¡æ¯"""
        if not results:
            return ""

        # æ„å»º step_id -> tool_name æ˜ å°„
        tool_map = {}
        if plan:
            for step in plan:
                tool_map[step.get('step_id')] = step.get('tool_name', '')

        formatted = []
        for r in results:
            step_id = r.get('step_id', '?')
            tool_name = tool_map.get(step_id, '')

            # è¿‡æ»¤ï¼šè·³è¿‡å†…éƒ¨å·¥å…·çš„ç»“æœ
            if tool_name in EXCLUDE_TOOLS_FROM_RESPONSE:
                logger.debug(f"è¿‡æ»¤æ­¥éª¤{step_id}çš„ç»“æœï¼ˆå·¥å…·: {tool_name}ï¼‰")
                continue

            success = r.get('success', False)
            output = r.get('output', '')
            error = r.get('error')

            if success:
                # æ ¼å¼åŒ–è¾“å‡º
                if isinstance(output, dict):
                    # è¿‡æ»¤æ•æ„Ÿå­—æ®µ
                    filtered_output = self._filter_sensitive_fields(output)
                    output_str = self._format_dict_output(filtered_output)
                elif isinstance(output, list):
                    output_str = self._format_list_output(output)
                else:
                    output_str = str(output)
                formatted.append(f"æ­¥éª¤{step_id}: {output_str}")
            else:
                formatted.append(f"æ­¥éª¤{step_id}: æ‰§è¡Œå¤±è´¥ - {error}")

        return "\n\n".join(formatted)

    def _filter_sensitive_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è¿‡æ»¤å­—å…¸ä¸­çš„æ•æ„Ÿå­—æ®µ"""
        filtered = {}
        for key, value in data.items():
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ•æ„Ÿå­—æ®µ
            if any(sensitive in key.lower() for sensitive in SENSITIVE_FIELDS):
                continue
            # é€’å½’å¤„ç†åµŒå¥—å­—å…¸
            if isinstance(value, dict):
                filtered[key] = self._filter_sensitive_fields(value)
            else:
                filtered[key] = value
        return filtered
    
    def _format_dict_output(self, data: Dict[str, Any], max_items: int = 20) -> str:
        """æ ¼å¼åŒ–å­—å…¸è¾“å‡º"""
        items = list(data.items())[:max_items]
        lines = [f"  - {k}: {v}" for k, v in items]
        if len(data) > max_items:
            lines.append(f"  ... å…±{len(data)}é¡¹")
        return "\n".join(lines)
    
    def _format_list_output(self, data: List[Any], max_items: int = 10) -> str:
        """æ ¼å¼åŒ–åˆ—è¡¨è¾“å‡º"""
        items = data[:max_items]
        lines = [f"  {i+1}. {item}" for i, item in enumerate(items)]
        if len(data) > max_items:
            lines.append(f"  ... å…±{len(data)}é¡¹")
        return "\n".join(lines)
    
    def _format_plan_summary(self, plan: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–è®¡åˆ’æ‘˜è¦"""
        if not plan:
            return ""

        steps = []
        for step in plan:
            step_id = step.get('step_id', '?')
            description = step.get('description', '')
            status = step.get('status', 'pending')
            steps.append(f"{step_id}. {description} [{status}]")

        return "\n".join(steps)

    def _format_chat_history(self, chat_history: List[Dict[str, str]], max_turns: int = 2) -> str:
        """æ ¼å¼åŒ–èŠå¤©å†å²ï¼Œé™åˆ¶æœ€è¿‘Nè½®å¯¹è¯"""
        if not chat_history:
            return ""

        # æœ€è¿‘Nè½®å¯¹è¯ï¼ˆæ¯è½®åŒ…å«userå’Œassistantå„ä¸€æ¡ï¼‰
        recent = chat_history[-max_turns * 2:]
        formatted = []
        for msg in recent:
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')
            # é™åˆ¶æ¯æ¡æ¶ˆæ¯é•¿åº¦ï¼Œé¿å…è¿‡é•¿
            if len(content) > 200:
                content = content[:200] + "..."
            formatted.append(f"{role}: {content}")

        return "\n".join(formatted)
    
    def _format_documents(self, documents: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æ–‡æ¡£æ‘˜è¦ï¼ŒåŒ…å«æ¥æºä¿¡æ¯ä¾›LLMå¼•ç”¨"""
        if not documents:
            return ""

        formatted = []
        for i, doc in enumerate(documents[:5], 1):
            # ä¸æˆªæ–­å†…å®¹ï¼Œä¿ç•™å®Œæ•´çš„çŸ¥è¯†åº“æ£€ç´¢ç»“æœ
            content = doc.get('content', '')
            metadata = doc.get('metadata', {})

            # è·å–æ¥æºä¿¡æ¯
            source_url = metadata.get('source', '')  # ç½‘ç»œæœç´¢URL
            doc_name = metadata.get('doc_name', '')  # çŸ¥è¯†åº“æ–‡æ¡£å
            category = metadata.get('category', '')  # çŸ¥è¯†åº“ç±»åˆ«
            title = metadata.get('title', '')

            # æ„å»ºæ¥æºæ ‡è¯†
            if source_url and source_url.startswith('http'):
                # ç½‘ç»œæœç´¢ç»“æœ
                source_label = f"ç½‘ç»œæ¥æº: {title or source_url}"
                source_ref = f"[{title or 'ç½‘ç»œé“¾æ¥'}]({source_url})"
            else:
                # çŸ¥è¯†åº“æ–‡æ¡£ - ç”Ÿæˆå®Œæ•´URL
                kb_id = category or 'unknown'
                display_name = doc_name or kb_id
                source_label = f"çŸ¥è¯†åº“: {kb_id}, æ–‡æ¡£: {doc_name}"
                if doc_name:
                    # ä½¿ç”¨å®Œæ•´URLç¡®ä¿é“¾æ¥æ­£ç¡®
                    source_ref = f"[{display_name}](http://localhost:8000/knowledge/kb-doc/{kb_id}/{doc_name})"
                else:
                    source_ref = f"çŸ¥è¯†åº“-{kb_id}"

            formatted.append(f"[{i}] æ¥æº: {source_label}\næ¥æºå¼•ç”¨æ ¼å¼: {source_ref}\nå†…å®¹: {content}")

        return "\n\n".join(formatted)


# åˆ›å»ºå…¨å±€Controllerå®ä¾‹
_controller_instance: Optional[Controller] = None


def get_controller() -> Controller:
    """è·å–Controllerå•ä¾‹"""
    global _controller_instance
    if _controller_instance is None:
        _controller_instance = Controller()
    return _controller_instance


async def controller_node(state: AgentState) -> Dict[str, Any]:
    """
    LangGraphèŠ‚ç‚¹å‡½æ•° - æ§åˆ¶èŠ‚ç‚¹
    
    åˆæˆæœ€ç»ˆå“åº”
    """
    controller = get_controller()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯éœ€è¦å¤„ç†
    if state.get('error') and not state.get('execution_results'):
        return await controller.handle_error_response(state)
    
    # åˆæˆå“åº”
    return await controller.synthesize_response(state)
