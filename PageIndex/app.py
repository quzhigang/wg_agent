import streamlit as st
import os
import re
import json
import asyncio
from datetime import datetime
from pageindex import page_index_main, config
from pageindex.page_index_md import md_to_tree
from pageindex.utils import ConfigLoader, ChatGPT_API, ChatGPT_API_async, get_text_of_pages, remove_fields
from pageindex.kb_manager import get_kb_manager, KnowledgeBaseInfo
import pandas as pd

# å›¾ç‰‡å¼•ç”¨æ­£åˆ™è¡¨è¾¾å¼: \n\n![](images/å›¾ç‰‡ç¼–ç .jpg)  \nå›¾X.X-Xå›¾å  \n
IMAGE_PATTERN = re.compile(r'\n\n!\[\]\(images/([a-zA-Z0-9]+)\.jpg\)\s*\n')
# å®Œæ•´åŒ¹é…ï¼šå›¾ç‰‡å¼•ç”¨ + å›¾åè¡Œ
IMAGE_WITH_CAPTION_PATTERN = re.compile(r'\n\n!\[\]\(images/([a-zA-Z0-9]+)\.jpg\)\s*\n(å›¾[\d\.\-]+\s*[^\n]*)\s*\n?')


def remove_image_references(text: str) -> str:
    """åˆ é™¤æ–‡æœ¬ä¸­çš„æ‰€æœ‰å›¾ç‰‡å¼•ç”¨å’Œå›¾å"""
    if not text:
        return text
    # å…ˆåˆ é™¤å¸¦å›¾åçš„å®Œæ•´å¼•ç”¨
    text = IMAGE_WITH_CAPTION_PATTERN.sub('\n', text)
    # å†åˆ é™¤å¯èƒ½æ®‹ç•™çš„å•ç‹¬å›¾ç‰‡å¼•ç”¨
    text = IMAGE_PATTERN.sub('\n', text)
    return text

st.set_page_config(page_title="PageIndex ç½‘é¡µç•Œé¢", page_icon="ğŸŒ²", layout="wide")

# å‡å°‘é¡µé¢é¡¶éƒ¨ç©ºç™½ï¼Œå¹¶è®¾ç½®ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨ä¸ºæ»šåŠ¨æ˜¾ç¤º
st.markdown("""
<style>
    .block-container {
        padding-top: 1rem;
        padding-bottom: 0rem;
    }
    header {
        visibility: hidden;
    }
    .stMainBlockContainer {
        padding-top: 1rem;
    }
    /* ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨æ»šåŠ¨æ˜¾ç¤º */
    [data-testid="stFileUploaderDropzoneInput"] + div {
        max-height: 200px;
        overflow-y: auto;
    }
    /* ä¸Šä¼ æ–‡ä»¶é¢„è§ˆåŒºåŸŸæ»šåŠ¨ */
    .stFileUploader > div > div:last-child {
        max-height: 150px;
        overflow-y: auto;
    }
</style>
""", unsafe_allow_html=True)

# Helper Functions
def update_api_config(api_key, api_base):
    os.environ["CHATGPT_API_KEY"] = api_key
    os.environ["CHATGPT_API_BASE"] = api_base
    import pageindex.utils
    pageindex.utils.CHATGPT_API_KEY = api_key
    pageindex.utils.CHATGPT_API_BASE = api_base

def get_file_size_str(size_bytes):
    """å°†å­—èŠ‚å¤§å°è½¬æ¢ä¸ºå¯è¯»æ ¼å¼"""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.2f} KB"
    else:
        return f"{size_bytes / (1024 * 1024):.2f} MB"

def get_file_type(filename):
    """è·å–æ–‡ä»¶ç±»å‹æè¿°"""
    ext = os.path.splitext(filename)[1].lower()
    type_map = {
        '.pdf': 'PDF æ–‡æ¡£',
        '.md': 'Markdown æ–‡æ¡£',
        '.markdown': 'Markdown æ–‡æ¡£'
    }
    return type_map.get(ext, 'æœªçŸ¥ç±»å‹')

def get_uploaded_files_info(upload_dir):
    """è·å–å·²ä¸Šä¼ æ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯"""
    files_info = []
    if os.path.exists(upload_dir):
        for idx, filename in enumerate(os.listdir(upload_dir), 1):
            filepath = os.path.join(upload_dir, filename)
            if os.path.isfile(filepath):
                stat = os.stat(filepath)
                files_info.append({
                    'åºå·': idx,
                    'æ–‡ä»¶å': filename,
                    'ä¸Šä¼ æ—¶é—´': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                    'æ–‡ä»¶å¤§å°': get_file_size_str(stat.st_size),
                    'æ–‡ä»¶ç±»å‹': get_file_type(filename)
                })
    return files_info

def check_duplicate_files(uploaded_files, upload_dir):
    """æ£€æµ‹é‡å¤æ–‡ä»¶"""
    duplicates = []
    if os.path.exists(upload_dir):
        existing_files = set(os.listdir(upload_dir))
        for uploaded_file in uploaded_files:
            if uploaded_file.name in existing_files:
                duplicates.append(uploaded_file.name)
    return duplicates


def get_node_mapping(structure, mapping=None):
    """ä»æ ‘ç»“æ„ä¸­æ„å»º node_id åˆ°èŠ‚ç‚¹çš„æ˜ å°„"""
    if mapping is None: 
        mapping = {}
    if isinstance(structure, list):
        for item in structure:
            get_node_mapping(item, mapping)
    elif isinstance(structure, dict):
        if 'node_id' in structure:
            mapping[structure['node_id']] = structure
        if 'nodes' in structure:
            get_node_mapping(structure['nodes'], mapping)
    return mapping


def load_document_structure(doc_name: str, results_dir: str):
    """åŠ è½½æ–‡æ¡£çš„ç»“æ„ JSON æ–‡ä»¶"""
    possible_names = [
        f"{doc_name}_structure.json",
        f"{doc_name.replace('.pdf', '')}_structure.json",
        f"{doc_name.replace('.md', '')}_structure.json",
    ]
    
    for name in possible_names:
        path = os.path.join(results_dir, name)
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
    return None


# ä¾§è¾¹æ é…ç½®
st.sidebar.header("æ¨¡å‹é…ç½®")
# ç»Ÿä¸€ä½¿ç”¨æœ¬é¡¹ç›®çš„é…ç½®ï¼ˆå…¼å®¹ä¸¤ç§ç¯å¢ƒå˜é‡åï¼‰
api_key = st.sidebar.text_input("API å¯†é’¥", value=os.getenv("OPENAI_API_KEY") or os.getenv("CHATGPT_API_KEY", ""), type="password")
api_base = st.sidebar.text_input("API åŸºç¡€åœ°å€", value=os.getenv("OPENAI_API_BASE") or os.getenv("CHATGPT_API_BASE", "https://api.openai.com/v1"))

config_loader = ConfigLoader()
default_config = config_loader.load()
# ç»Ÿä¸€ä½¿ç”¨æœ¬é¡¹ç›®çš„é…ç½®ï¼ˆå…¼å®¹ä¸¤ç§ç¯å¢ƒå˜é‡åï¼‰
model_name = st.sidebar.text_input("æ¨¡å‹åç§°", value=os.getenv("OPENAI_MODEL_NAME") or os.getenv("CHATGPT_MODEL", "gpt-4o"))

st.sidebar.header("PageIndex é…ç½®")
toc_check_pages = st.sidebar.number_input("ç›®å½•æ£€æŸ¥é¡µæ•°", value=default_config.toc_check_page_num)
max_pages_per_node = st.sidebar.number_input("æ¯èŠ‚ç‚¹æœ€å¤§é¡µæ•°", value=default_config.max_page_num_each_node)
max_tokens_per_node = st.sidebar.number_input("æ¯èŠ‚ç‚¹æœ€å¤§ä»¤ç‰Œæ•°", value=default_config.max_token_num_each_node)

st.sidebar.header("å‘é‡æ£€ç´¢é…ç½®")
vector_top_k = st.sidebar.slider("æ£€ç´¢ç»“æœæ•°é‡ (Top-K)", min_value=1, max_value=50, value=10)

# é»˜è®¤è®¾ç½®
if_add_doc_description = "no"
if_add_node_text = "no"

# åŸç†ä»‹ç»å†…å®¹
PRINCIPLE_CONTENT = """
## PageIndex æ£€ç´¢åŸç†å¯¹æ¯”

### ä¸€ã€ä¸‰ç§æ£€ç´¢æ–¹å¼å¯¹æ¯”
| ç‰¹æ€§ | ä¼ ç»Ÿå‘é‡æ£€ç´¢ | PageIndex åŸç‰ˆï¼ˆVectorlessï¼‰ | æœ¬æ¬¡ä¼˜åŒ–ï¼ˆæ··åˆæ£€ç´¢ï¼‰ |
|------|-------------|---------------------------|-------------------|
| ç´¢å¼•æ–¹å¼ | æ–‡æ¡£åˆ‡ç‰‡ â†’ å‘é‡åŒ– | æ–‡æ¡£ â†’ ç›®å½•æ ‘ç»“æ„ | ç›®å½•æ ‘ + èŠ‚ç‚¹å‘é‡ |
| æ£€ç´¢æ–¹å¼ | å‘é‡ç›¸ä¼¼åº¦åŒ¹é… | LLM æ¨ç†å®šä½ | å‘é‡å¬å› + ç»“æ„å®šä½ |
| Token æ¶ˆè€— | 0ï¼ˆæ£€ç´¢é˜¶æ®µï¼‰ | é«˜ï¼ˆæ¯æ¬¡æŸ¥è¯¢éœ€å¤šæ¬¡ LLM è°ƒç”¨ï¼‰ | 0ï¼ˆæ£€ç´¢é˜¶æ®µï¼‰ |
| æ£€ç´¢é€Ÿåº¦ | æ¯«ç§’çº§ | ç§’çº§ï¼ˆä¾èµ– LLM å“åº”ï¼‰ | æ¯«ç§’çº§ |
| ä¸Šä¸‹æ–‡ä¿ç•™ | å·®ï¼ˆåˆ‡ç‰‡ç ´åä¸Šä¸‹æ–‡ï¼‰ | ä¼˜ï¼ˆä¿ç•™æ–‡æ¡£å±‚çº§ç»“æ„ï¼‰ | ä¼˜ï¼ˆä¿ç•™ç»“æ„ä¿¡æ¯ï¼‰ |
| è¯­ä¹‰ç†è§£ | æµ…å±‚ï¼ˆå‘é‡ç›¸ä¼¼åº¦ï¼‰ | æ·±å±‚ï¼ˆLLM æ¨ç†ï¼‰ | ä¸­ç­‰ï¼ˆå‘é‡ + æ‘˜è¦ï¼‰ |

### äºŒã€PageIndex åŸç‰ˆæ£€ç´¢åŸç†ï¼ˆVectorless RAGï¼‰
**æ ¸å¿ƒç†å¿µ**ï¼šä¸å¯¹æ–‡æ¡£è¿›è¡Œå‘é‡åŒ–ï¼Œè€Œæ˜¯åˆ©ç”¨ LLM çš„æ¨ç†èƒ½åŠ›åœ¨æ–‡æ¡£ç›®å½•ç»“æ„ä¸­å®šä½ä¿¡æ¯ã€‚

**æ£€ç´¢æµç¨‹**ï¼š
```
ç”¨æˆ·æŸ¥è¯¢ 
    â†“
1. LLM ç­›é€‰ç›¸å…³æ–‡æ¡£ï¼ˆæ ¹æ®æ–‡æ¡£åç§°å’Œæè¿°ï¼‰
    â†“
2. LLM åœ¨ç›®å½•æ ‘ä¸­æ¨ç†å®šä½ï¼ˆä¼ é€’å®Œæ•´æ ‘ç»“æ„ç»™ LLMï¼‰
    â†“
3. æ ¹æ®å®šä½çš„èŠ‚ç‚¹æå–åŸæ–‡ï¼ˆstart_index â†’ end_indexï¼‰
    â†“
4. LLM ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
```

**ä¼˜ç‚¹**ï¼š
- ä¿ç•™æ–‡æ¡£çš„å±‚çº§ç»“æ„å’Œä¸Šä¸‹æ–‡å…³ç³»
- LLM å¯ä»¥è¿›è¡Œæ·±å±‚è¯­ä¹‰æ¨ç†
- ä¸éœ€è¦å‘é‡æ•°æ®åº“

**ç¼ºç‚¹**ï¼š
- æ¯æ¬¡æŸ¥è¯¢æ¶ˆè€—å¤§é‡ Tokenï¼ˆéœ€è¦ä¼ é€’å®Œæ•´æ ‘ç»“æ„ï¼‰  
- æ£€ç´¢é€Ÿåº¦æ…¢ï¼ˆä¾èµ– LLM å“åº”æ—¶é—´ï¼‰
- æ–‡æ¡£æ•°é‡å¢å¤šæ—¶ï¼ŒToken æ¶ˆè€—çº¿æ€§å¢é•¿

### ä¸‰ã€ä¼ ç»Ÿå‘é‡æ£€ç´¢åŸç†
**æ ¸å¿ƒç†å¿µ**ï¼šå°†æ–‡æ¡£åˆ‡åˆ†ä¸ºå›ºå®šå¤§å°çš„å—ï¼Œå‘é‡åŒ–åé€šè¿‡ç›¸ä¼¼åº¦åŒ¹é…æ£€ç´¢ã€‚

**æ£€ç´¢æµç¨‹**ï¼š
```
ç”¨æˆ·æŸ¥è¯¢ 
    â†“
1. æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ–
    â†“
2. å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ Top-K æ–‡æ¡£å—
    â†“
3. æ‹¼æ¥æ£€ç´¢åˆ°çš„æ–‡æ¡£å—
    â†“
4. LLM ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
```

**ä¼˜ç‚¹**ï¼š
- æ£€ç´¢é€Ÿåº¦å¿«ï¼ˆæ¯«ç§’çº§ï¼‰
- æ£€ç´¢é˜¶æ®µä¸æ¶ˆè€— Token

**ç¼ºç‚¹**ï¼š
- åˆ‡ç‰‡ç ´åæ–‡æ¡£ä¸Šä¸‹æ–‡
- æ— æ³•ç†è§£æ–‡æ¡£å±‚çº§ç»“æ„
- å¯èƒ½æ£€ç´¢åˆ°ä¸ç›¸å…³çš„ç‰‡æ®µ

### å››ã€æœ¬ç³»ç»Ÿä¼˜åŒ–æ–¹æ¡ˆï¼ˆæ··åˆæ£€ç´¢ï¼‰
**æ ¸å¿ƒç†å¿µ**ï¼šç»“åˆå‘é‡æ£€ç´¢çš„é€Ÿåº¦ä¼˜åŠ¿å’Œç›®å½•æ ‘ç»“æ„çš„ä¸Šä¸‹æ–‡ä¼˜åŠ¿ã€‚

**æ£€ç´¢æµç¨‹**ï¼š
```
ç”¨æˆ·æŸ¥è¯¢ 
    â†“
1. æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ–
    â†“
2. å‘é‡æ£€ç´¢ Top-K ç›¸å…³èŠ‚ç‚¹ï¼ˆåŸºäºèŠ‚ç‚¹æ ‡é¢˜+æ‘˜è¦çš„å‘é‡ï¼‰
    â†“
3. æ ¹æ®èŠ‚ç‚¹çš„ start_index/end_index æå–åŸæ–‡
    â†“
4. LLM ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
```

**ä¼˜ç‚¹**ï¼š
- æ£€ç´¢é€Ÿåº¦å¿«ï¼ˆæ¯«ç§’çº§ï¼‰
- æ£€ç´¢é˜¶æ®µä¸æ¶ˆè€— Token
- ä¿ç•™äº†æ–‡æ¡£çš„å±‚çº§ç»“æ„ä¿¡æ¯
- æ¯ä¸ªèŠ‚ç‚¹æœ‰å®Œæ•´çš„ä¸Šä¸‹æ–‡ï¼ˆä¸æ˜¯éšæœºåˆ‡ç‰‡ï¼‰

**å…³é”®å·®å¼‚**ï¼š
- å‘é‡åŒ–çš„æ˜¯èŠ‚ç‚¹æ‘˜è¦è€ŒéåŸæ–‡åˆ‡ç‰‡
- æ£€ç´¢å•ä½æ˜¯ç›®å½•èŠ‚ç‚¹è€Œéå›ºå®šå¤§å°çš„å—
- ä¿ç•™äº†èŠ‚ç‚¹çš„å±‚çº§è·¯å¾„å’Œé¡µç èŒƒå›´ä¿¡æ¯
"""

# æ ‡é¢˜å’ŒåŸç†ä»‹ç»æŒ‰é’®
col_title, col_info = st.columns([6, 1])
with col_title:
    st.title("ğŸŒ² PageIndex + Vector æ™ºèƒ½RAGæ£€ç´¢ç³»ç»Ÿ")
with col_info:
    st.write("")  # å ä½ï¼Œä½¿æŒ‰é’®å‚ç›´å±…ä¸­
    if st.button("â„¹ï¸ åŸç†ä»‹ç»", help="ç‚¹å‡»æŸ¥çœ‹æ£€ç´¢åŸç†"):
        st.session_state.show_principle = True

# åŸç†ä»‹ç»å¼¹çª—
if st.session_state.get("show_principle", False):
    @st.dialog("ğŸ“– PageIndex æ£€ç´¢åŸç†ä»‹ç»", width="large")
    def show_principle_dialog():
        st.markdown(PRINCIPLE_CONTENT)
        if st.button("å…³é—­", type="primary"):
            st.session_state.show_principle = False
            st.rerun()
    show_principle_dialog()

tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ’¬ æ™ºèƒ½å¯¹è¯", "ğŸ“„ æ–‡æ¡£å¤„ç†", "ğŸ“š çŸ¥è¯†åº“ç®¡ç†", "ğŸ“Š å‘é‡ç´¢å¼•", "ğŸ” å‘é‡æ£€ç´¢"])

# ç›®å½•é…ç½®ï¼ˆç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•ï¼‰
# å½“ä»PageIndexç›®å½•è¿è¡Œæ—¶ä½¿ç”¨ç›¸å¯¹è·¯å¾„ ./uploads å’Œ ./results
# å½“ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ—¶ä½¿ç”¨ ./PageIndex/uploads å’Œ ./PageIndex/results
_current_dir = os.path.dirname(os.path.abspath(__file__))
upload_dir = os.getenv("PAGEINDEX_UPLOAD_DIR", os.path.join(_current_dir, "uploads"))
results_dir = os.getenv("PAGEINDEX_RESULTS_DIR", os.path.join(_current_dir, "results"))
os.makedirs(upload_dir, exist_ok=True)
os.makedirs(results_dir, exist_ok=True)

# é€‰é¡¹å¡ 2: æ–‡æ¡£å¤„ç†
with tab2:
    st.header("å¤„ç†æ–°æ–‡æ¡£")

    # çŸ¥è¯†åº“é€‰æ‹©
    kb_manager_tab1 = get_kb_manager()
    kb_list_tab1 = kb_manager_tab1.list_all()

    if not kb_list_tab1:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ã€ŒçŸ¥è¯†åº“ç®¡ç†ã€é€‰é¡¹å¡ä¸­åˆ›å»ºçŸ¥è¯†åº“ï¼Œç„¶åå†ä¸Šä¼ æ–‡æ¡£ã€‚")
    else:
        # æ„å»ºçŸ¥è¯†åº“é€‰é¡¹
        kb_options = {f"{kb.name} ({kb.id})": kb.id for kb in kb_list_tab1}
        selected_kb_display = st.selectbox(
            "é€‰æ‹©ç›®æ ‡çŸ¥è¯†åº“",
            options=list(kb_options.keys()),
            help="æ–‡æ¡£å°†è¢«ä¿å­˜åˆ°æ‰€é€‰çŸ¥è¯†åº“ä¸­"
        )
        selected_kb_id = kb_options[selected_kb_display]

        # æ ¹æ®é€‰æ‹©çš„çŸ¥è¯†åº“è®¾ç½®ç›®å½•
        kb_upload_dir = kb_manager_tab1.get_uploads_dir(selected_kb_id)
        kb_results_dir = kb_manager_tab1.get_results_dir(selected_kb_id)
        os.makedirs(kb_upload_dir, exist_ok=True)
        os.makedirs(kb_results_dir, exist_ok=True)

        uploaded_files = st.file_uploader(
            "ä¸Šä¼ æ–‡ä»¶",
            type=["pdf", "md", "markdown"],
            accept_multiple_files=True,
            key="file_uploader"
        )

        # é‡å¤æ–‡ä»¶æ£€æµ‹
        if uploaded_files:
            duplicates = check_duplicate_files(uploaded_files, kb_upload_dir)
            if duplicates:
                st.warning(f"âš ï¸ æ£€æµ‹åˆ°é‡å¤æ–‡ä»¶ï¼ä»¥ä¸‹æ–‡ä»¶å·²å­˜åœ¨äºçŸ¥è¯†åº“ [{selected_kb_id}] ä¸­ï¼š\n\n**{', '.join(duplicates)}**\n\nç»§ç»­å¤„ç†å°†è¦†ç›–åŸæœ‰æ–‡ä»¶ã€‚")

            if st.button("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†"):
                if not api_key:
                    st.error("è¯·è¾“å…¥ API å¯†é’¥ï¼")
                else:
                    update_api_config(api_key, api_base)
                    total_files = len(uploaded_files)
                    # æ˜¾ç¤ºæ€»ä½“è¿›åº¦ä¿¡æ¯
                    overall_status = st.empty()
                    # å•æ–‡æ¡£è¿›åº¦æ¡
                    progress_bar = st.progress(0.0)
                    status_text = st.empty()
                    all_results_container = st.container()

                    for i, uploaded_file in enumerate(uploaded_files):
                        file_extension = os.path.splitext(uploaded_file.name)[1].lower()
                        overall_status.info(f"ğŸ“ æ€»è¿›åº¦: {i+1}/{total_files} ä¸ªæ–‡ä»¶")
                        status_text.text(f"æ­£åœ¨å¤„ç†: {uploaded_file.name}")
                        # é‡ç½®è¿›åº¦æ¡ä¸º0
                        progress_bar.progress(0.0)

                        try:
                            # é˜¶æ®µ1: ä¿å­˜æ–‡ä»¶ (10%)
                            progress_bar.progress(0.1)
                            file_path = os.path.join(kb_upload_dir, uploaded_file.name)
                            with open(file_path, "wb") as f:
                                f.write(uploaded_file.getvalue())

                            # é˜¶æ®µ2: å¼€å§‹å¤„ç† (20%)
                            progress_bar.progress(0.2)
                            result = None
                            if file_extension == ".pdf":
                                # é˜¶æ®µ3: PDFè§£æä¸­ (40%)
                                progress_bar.progress(0.4)
                                opt = config(
                                    model=model_name,
                                    toc_check_page_num=toc_check_pages,
                                    max_page_num_each_node=max_pages_per_node,
                                    max_token_num_each_node=max_tokens_per_node,
                                    if_add_node_id="yes",
                                    if_add_node_summary="yes",
                                    if_add_doc_description=if_add_doc_description,
                                    if_add_node_text=if_add_node_text,
                                    if_build_vector_index="no"  # ç¦ç”¨è‡ªåŠ¨ç´¢å¼•ï¼Œæ”¹ç”¨å¤šçŸ¥è¯†åº“ç´¢å¼•
                                )
                                result = page_index_main(file_path, opt)
                            elif file_extension in [".md", ".markdown"]:
                                # é˜¶æ®µ3: Markdownè§£æä¸­ (40%)
                                progress_bar.progress(0.4)
                                result = asyncio.run(md_to_tree(
                                    md_path=file_path,
                                    if_thinning=False,
                                    if_add_node_summary=True,
                                    model=model_name,
                                    if_add_doc_description=(if_add_doc_description == "yes"),
                                    if_add_node_text=True,  # Markdown æ–‡ä»¶å¼ºåˆ¶ä¿ç•™å®Œæ•´æ–‡æœ¬ä»¥æ”¯æŒæ£€ç´¢
                                    if_add_node_id=True,
                                    if_build_vector_index=False  # ç¦ç”¨è‡ªåŠ¨ç´¢å¼•ï¼Œæ”¹ç”¨å¤šçŸ¥è¯†åº“ç´¢å¼•
                                ))

                            # é˜¶æ®µ4: ç”Ÿæˆæ‘˜è¦ä¸­ (70%)
                            progress_bar.progress(0.7)

                            if result:
                                # é˜¶æ®µ5: ä¿å­˜ç»“æœå¹¶æ„å»ºå¤šçŸ¥è¯†åº“å‘é‡ç´¢å¼• (90%)
                                progress_bar.progress(0.9)
                                file_base_name = os.path.splitext(uploaded_file.name)[0]
                                result_file_path = os.path.join(kb_results_dir, f"{file_base_name}_structure.json")
                                with open(result_file_path, "w", encoding="utf-8") as f:
                                    json.dump(result, f, indent=2, ensure_ascii=False)

                                # æ„å»ºå¤šçŸ¥è¯†åº“å‘é‡ç´¢å¼•
                                from pageindex.vector_index import get_multi_kb_vector_index
                                multi_kb_index = get_multi_kb_vector_index()
                                kb_chroma_dir = kb_manager_tab1.get_chroma_dir(selected_kb_id)
                                doc_name = result.get("doc_name", file_base_name)
                                doc_description = result.get("doc_description", "")
                                structure = result.get("structure", [])
                                multi_kb_index.add_document(
                                    selected_kb_id, kb_chroma_dir, doc_name, structure, doc_description
                                )

                                # é˜¶æ®µ6: å®Œæˆ (100%)
                                progress_bar.progress(1.0)
                                with all_results_container:
                                    with st.expander(f"âœ… {uploaded_file.name} å¤„ç†æˆåŠŸ", expanded=False):
                                        st.info(f"JSON å·²è‡ªåŠ¨ä¿å­˜è‡³: {result_file_path}")
                                        st.json(result)
                        except Exception as e:
                            progress_bar.progress(1.0)
                            with all_results_container:
                                st.error(f"âŒ {uploaded_file.name} å¤„ç†å‡ºé”™: {str(e)}")

                    overall_status.success(f"ğŸ‰ æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆï¼å…±å¤„ç† {total_files} ä¸ªæ–‡ä»¶")
                    status_text.empty()
                    progress_bar.empty()
                    st.balloons()

        # æ–‡ä»¶è¯¦ç»†æ¸…å•
        st.markdown("---")
        files_info = get_uploaded_files_info(kb_upload_dir)

        # æ ‡é¢˜å’Œåˆ é™¤æŒ‰é’®åœ¨åŒä¸€è¡Œ
        col_title, col_btn = st.columns([4, 1])
        with col_title:
            st.subheader(f"ğŸ“‹ å·²å¤„ç†æ–‡ä»¶æ¸…å• - {selected_kb_display}")

        if files_info:
            file_names = [f['æ–‡ä»¶å'] for f in files_info]

            # åˆå§‹åŒ–é€‰ä¸­çŠ¶æ€
            if "selected_files" not in st.session_state:
                st.session_state.selected_files = {name: False for name in file_names}

            # åŒæ­¥æ–°æ–‡ä»¶åˆ°é€‰ä¸­çŠ¶æ€
            for name in file_names:
                if name not in st.session_state.selected_files:
                    st.session_state.selected_files[name] = False

            with col_btn:
                if st.button("ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­", type="secondary"):
                    deleted_files = []
                    from pageindex.vector_index import get_multi_kb_vector_index
                    multi_kb_index = get_multi_kb_vector_index()
                    kb_chroma_dir = kb_manager_tab1.get_chroma_dir(selected_kb_id)

                    for filename, selected in st.session_state.selected_files.items():
                        if selected:
                            # åˆ é™¤åŸå§‹æ–‡ä»¶
                            file_path = os.path.join(kb_upload_dir, filename)
                            if os.path.exists(file_path):
                                os.remove(file_path)

                            # åˆ é™¤å¯¹åº”çš„ç´¢å¼• JSON æ–‡ä»¶
                            file_base_name = os.path.splitext(filename)[0]
                            json_path = os.path.join(kb_results_dir, f"{file_base_name}_structure.json")
                            if os.path.exists(json_path):
                                os.remove(json_path)

                            # åˆ é™¤å‘é‡ç´¢å¼•
                            try:
                                multi_kb_index.delete_document(selected_kb_id, kb_chroma_dir, file_base_name)
                            except Exception as e:
                                st.warning(f"åˆ é™¤ {file_base_name} çš„å‘é‡ç´¢å¼•å¤±è´¥: {e}")

                            deleted_files.append(filename)

                    if deleted_files:
                        st.success(f"å·²åˆ é™¤ {len(deleted_files)} ä¸ªæ–‡ä»¶")
                        st.session_state.selected_files = {}
                        st.rerun()
                    else:
                        st.warning("è¯·å…ˆé€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶")

            # ä½¿ç”¨ data_editor å®ç°ç´§å‡‘çš„å¯é€‰æ‹©è¡¨æ ¼ï¼Œè®¾ç½®å›ºå®šé«˜åº¦å®ç°æ»šåŠ¨
            df = pd.DataFrame(files_info)
            df.insert(0, 'é€‰æ‹©', False)

            # å°†åºå·è½¬ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿å±…ä¸­æ˜¾ç¤º
            df['åºå·'] = df['åºå·'].astype(str)

            # è®¡ç®—è¡¨æ ¼é«˜åº¦ï¼šæ¯è¡Œçº¦35pxï¼Œè¡¨å¤´çº¦35pxï¼Œæœ€å¤§æ˜¾ç¤º10è¡Œ
            table_height = min(len(files_info) * 35 + 35, 400)

            edited_df = st.data_editor(
                df,
                column_config={
                    "é€‰æ‹©": st.column_config.CheckboxColumn(
                        "é€‰æ‹©",
                        help="é€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶",
                        default=False,
                    ),
                    "åºå·": st.column_config.TextColumn("åºå·", width="small"),
                    "æ–‡ä»¶å": st.column_config.TextColumn("æ–‡ä»¶å", width="medium"),
                    "ä¸Šä¼ æ—¶é—´": st.column_config.TextColumn("ä¸Šä¼ æ—¶é—´", width="medium"),
                    "æ–‡ä»¶å¤§å°": st.column_config.TextColumn("å¤§å°", width="small"),
                    "æ–‡ä»¶ç±»å‹": st.column_config.TextColumn("ç±»å‹", width="small"),
                },
                disabled=["åºå·", "æ–‡ä»¶å", "ä¸Šä¼ æ—¶é—´", "æ–‡ä»¶å¤§å°", "æ–‡ä»¶ç±»å‹"],
                hide_index=True,
                use_container_width=True,
                height=table_height,
                key="file_table"
            )

            # æ›´æ–°é€‰ä¸­çŠ¶æ€
            for idx, row in edited_df.iterrows():
                st.session_state.selected_files[row['æ–‡ä»¶å']] = row['é€‰æ‹©']

            st.caption(f"å…± {len(files_info)} ä¸ªæ–‡ä»¶")
        else:
            with col_btn:
                st.empty()
            st.info("æš‚æ— å·²ä¸Šä¼ çš„æ–‡ä»¶ã€‚è¯·ä¸Šä¼ æ–‡ä»¶è¿›è¡Œå¤„ç†ã€‚")

# é€‰é¡¹å¡ 1: æ™ºèƒ½å¯¹è¯ (RAG) - ä½¿ç”¨å‘é‡æ£€ç´¢
with tab1:
    # çŸ¥è¯†åº“å¤šé€‰
    kb_manager_tab2 = get_kb_manager()
    kb_list_tab2 = kb_manager_tab2.list_all()

    if not kb_list_tab2:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ã€ŒçŸ¥è¯†åº“ç®¡ç†ã€é€‰é¡¹å¡ä¸­åˆ›å»ºçŸ¥è¯†åº“å¹¶ä¸Šä¼ æ–‡æ¡£ã€‚")
    else:
        # çŸ¥è¯†åº“å¤é€‰æ¡†åˆ—è¡¨
        st.subheader("é€‰æ‹©æ£€ç´¢çš„çŸ¥è¯†åº“")

        # åˆå§‹åŒ–æ‰€æœ‰çŸ¥è¯†åº“çš„é€‰ä¸­çŠ¶æ€ï¼ˆé¦–æ¬¡åŠ è½½æ—¶é»˜è®¤é€‰ä¸­ï¼‰
        for kb in kb_list_tab2:
            if f"kb_cb_{kb.id}" not in st.session_state:
                st.session_state[f"kb_cb_{kb.id}"] = True

        # åˆå§‹åŒ–å…¨é€‰å¤é€‰æ¡†çŠ¶æ€
        if "select_all_kb_state" not in st.session_state:
            st.session_state.select_all_kb_state = True

        # å…¨é€‰å¤é€‰æ¡†å›è°ƒå‡½æ•°
        def on_select_all_change():
            new_value = st.session_state.select_all_kb_checkbox
            for kb in kb_list_tab2:
                st.session_state[f"kb_cb_{kb.id}"] = new_value
            st.session_state.select_all_kb_state = new_value

        # å…¨é€‰å¤é€‰æ¡†
        col_select_all, col_spacer = st.columns([1, 5])
        with col_select_all:
            st.checkbox(
                "å…¨é€‰",
                value=st.session_state.select_all_kb_state,
                key="select_all_kb_checkbox",
                on_change=on_select_all_change
            )

        # æ¨ªå‘æ’åˆ—çŸ¥è¯†åº“å¤é€‰æ¡†ï¼Œæ¯è¡Œ4åˆ—
        cols_per_row = 4
        kb_selections = {}

        for i in range(0, len(kb_list_tab2), cols_per_row):
            cols = st.columns(cols_per_row)
            for j, col in enumerate(cols):
                kb_idx = i + j
                if kb_idx < len(kb_list_tab2):
                    kb = kb_list_tab2[kb_idx]
                    with col:
                        kb_selections[kb.id] = st.checkbox(
                            f"ğŸ“š {kb.name}",
                            key=f"kb_cb_{kb.id}",
                            help=kb.id
                        )

        # æ›´æ–°å…¨é€‰çŠ¶æ€ï¼ˆæ ¹æ®å„çŸ¥è¯†åº“çš„å®é™…é€‰ä¸­çŠ¶æ€ï¼‰
        all_selected_now = all(kb_selections.values()) if kb_selections else True
        if all_selected_now != st.session_state.select_all_kb_state:
            st.session_state.select_all_kb_state = all_selected_now

        # è·å–é€‰ä¸­çš„çŸ¥è¯†åº“IDåˆ—è¡¨
        selected_kb_ids = [kb_id for kb_id, selected in kb_selections.items() if selected]

        if not selected_kb_ids:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªçŸ¥è¯†åº“è¿›è¡Œæ£€ç´¢ã€‚")
        else:
            # æ£€æŸ¥é€‰ä¸­çŸ¥è¯†åº“çš„å‘é‡ç´¢å¼•çŠ¶æ€
            from pageindex.vector_index import get_multi_kb_vector_index
            multi_kb_index = get_multi_kb_vector_index()

            total_nodes = 0
            total_docs = 0
            for kb_id in selected_kb_ids:
                kb_chroma_dir = kb_manager_tab2.get_chroma_dir(kb_id)
                try:
                    stats = multi_kb_index.get_stats(kb_id, kb_chroma_dir)
                    total_nodes += stats.get("total_nodes", 0)
                    total_docs += stats.get("total_documents", 0)
                except Exception:
                    pass

            if total_nodes == 0:
                st.warning("æ‰€é€‰çŸ¥è¯†åº“çš„å‘é‡ç´¢å¼•ä¸ºç©ºã€‚è¯·å…ˆåœ¨ã€Œæ–‡æ¡£å¤„ç†ã€é€‰é¡¹å¡ä¸­ä¸Šä¼ æ–‡æ¡£ã€‚")
            else:
                st.success(f"âœ… å·²é€‰æ‹© {len(selected_kb_ids)} ä¸ªçŸ¥è¯†åº“ï¼š{total_docs} ä¸ªæ–‡æ¡£ï¼Œ{total_nodes} ä¸ªèŠ‚ç‚¹")

    # åˆå§‹åŒ–èŠå¤©å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # åˆ›å»ºèŠå¤©æ¶ˆæ¯å®¹å™¨
    chat_container = st.container()
    
    # èŠå¤©è¾“å…¥æ”¾åœ¨å®¹å™¨å¤–é¢ï¼ˆåº•éƒ¨ï¼‰
    query = st.chat_input("å‘æ•´ä¸ªæ–‡æ¡£åº“æé—®...")
    
    # åœ¨å®¹å™¨å†…æ˜¾ç¤ºèŠå¤©æ¶ˆæ¯
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                if "thinking" in message and message["thinking"]:
                    with st.expander("æ¨ç†æ£€ç´¢è¿‡ç¨‹"):
                        st.markdown(message["thinking"])
                if "nodes" in message and message["nodes"]:
                    with st.expander("å‚è€ƒæ¥æº"):
                        for node_info in message["nodes"]:
                            st.write(node_info)

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if query:
        if not api_key:
            st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API å¯†é’¥")
        elif not kb_list_tab2:
            st.error("è¯·å…ˆåˆ›å»ºçŸ¥è¯†åº“")
        elif not selected_kb_ids:
            st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªçŸ¥è¯†åº“")
        else:
            update_api_config(api_key, api_base)
            st.session_state.messages.append({"role": "user", "content": query})
            with st.chat_message("user"):
                st.markdown(query)

            with st.chat_message("assistant"):
                with st.status("æ­£åœ¨è¿›è¡Œå‘é‡æ£€ç´¢...", expanded=True) as status:
                    thinking_parts = []
                    all_reference_nodes = []
                    all_relevant_text = ""

                    # 1. å¤šçŸ¥è¯†åº“å‘é‡æ£€ç´¢ï¼ˆæ¯«ç§’çº§ï¼‰
                    st.write("1. å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢...")
                    try:
                        # æ„å»ºçŸ¥è¯†åº“é…ç½®åˆ—è¡¨
                        kb_configs = [
                            {"kb_id": kb_id, "chroma_dir": kb_manager_tab2.get_chroma_dir(kb_id)}
                            for kb_id in selected_kb_ids
                        ]
                        search_results = multi_kb_index.search_multi_kb(kb_configs, query, top_k=vector_top_k)
                        thinking_parts.append(f"å‘é‡æ£€ç´¢è¿”å› {len(search_results)} ä¸ªç›¸å…³èŠ‚ç‚¹")
                    except Exception as e:
                        st.error(f"å‘é‡æ£€ç´¢å¤±è´¥: {e}")
                        search_results = []

                    if search_results:
                        # æŒ‰çŸ¥è¯†åº“å’Œæ–‡æ¡£åˆ†ç»„
                        kb_doc_results = {}
                        for result in search_results:
                            kb_id = result.get("kb_id", "unknown")
                            doc_name = result["doc_name"]
                            key = (kb_id, doc_name)
                            if key not in kb_doc_results:
                                kb_doc_results[key] = []
                            kb_doc_results[key].append(result)

                        unique_kbs = set(r.get("kb_id") for r in search_results)
                        st.write(f"æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³èŠ‚ç‚¹ï¼Œæ¥è‡ª {len(unique_kbs)} ä¸ªçŸ¥è¯†åº“")

                        # 2. å†…å®¹æå–
                        st.write("2. æå–ç›¸å…³å†…å®¹...")
                        for (kb_id, doc_name), results in kb_doc_results.items():
                            # ä»å¯¹åº”çŸ¥è¯†åº“çš„ results ç›®å½•åŠ è½½ç»“æ„æ–‡ä»¶
                            kb_results_dir = kb_manager_tab2.get_results_dir(kb_id)
                            doc_data = load_document_structure(doc_name, kb_results_dir)
                            if not doc_data:
                                thinking_parts.append(f"[{kb_id}/{doc_name}] æœªæ‰¾åˆ°ç»“æ„æ–‡ä»¶")
                                continue

                            node_map = get_node_mapping(doc_data.get("structure", []))

                            # è·å–çŸ¥è¯†åº“æ˜¾ç¤ºåç§°
                            kb_info = kb_manager_tab2.get(kb_id)
                            kb_display_name = kb_info.name if kb_info else kb_id

                            for result in results:
                                node_id = result["node_id"]
                                title = result["title"]
                                score = result.get("score", 0)

                                all_reference_nodes.append(f"[{kb_display_name}] {doc_name} / {title} (ç›¸ä¼¼åº¦: {score:.3f})")

                                node = node_map.get(node_id)
                                if node and node.get("text"):
                                    # åˆ é™¤å›¾ç‰‡å¼•ç”¨åå†æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
                                    clean_text = remove_image_references(node['text'])
                                    all_relevant_text += f"\n--- çŸ¥è¯†åº“: {kb_display_name}, æ–‡æ¡£: {doc_name}, ç« èŠ‚: {title} ---\n{clean_text}\n"
                                elif result.get("summary"):
                                    # åˆ é™¤å›¾ç‰‡å¼•ç”¨åå†æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
                                    clean_summary = remove_image_references(result['summary'])
                                    all_relevant_text += f"\n--- çŸ¥è¯†åº“: {kb_display_name}, æ–‡æ¡£: {doc_name}, ç« èŠ‚: {title} (æ‘˜è¦) ---\n{clean_summary}\n"
                        
                        st.write("3. ç”Ÿæˆå›ç­”...")
                        status.update(label="å‘é‡æ£€ç´¢å®Œæˆ", state="complete", expanded=False)
                    else:
                        status.update(label="æœªæ‰¾åˆ°ç›¸å…³å†…å®¹", state="error", expanded=False)

                # 3. ç”Ÿæˆç­”æ¡ˆ
                if not all_relevant_text.strip():
                    full_answer = "æŠ±æ­‰ï¼Œæœªèƒ½ä»æ‰€é€‰çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„å†…å®¹ã€‚è¯·å°è¯•æ¢ä¸€ç§æ–¹å¼æé—®ï¼Œæˆ–é€‰æ‹©å…¶ä»–çŸ¥è¯†åº“ã€‚"
                else:
                    answer_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶åŠ©æ‰‹ã€‚ä½ æœ‰æ¥è‡ªå¤šä¸ªçŸ¥è¯†åº“çš„æ–‡æ¡£ç‰‡æ®µã€‚
æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœæ¥æºæœ‰å†²çªçš„ä¿¡æ¯ï¼Œè¯·æåŠã€‚
åœ¨å›ç­”ä¸­å§‹ç»ˆå¼•ç”¨çŸ¥è¯†åº“åç§°å’Œæ–‡æ¡£åç§°ã€‚

é—®é¢˜: {query}

ä¸Šä¸‹æ–‡:
{all_relevant_text[:15000]}

åŠ©æ‰‹:"""
                    try:
                        full_answer = ChatGPT_API(model=model_name, prompt=answer_prompt)
                    except Exception as e:
                        full_answer = f"ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}"
                
                st.markdown(full_answer)
                if all_reference_nodes:
                    with st.expander("å‚è€ƒæ¥æº"):
                        for node_info in all_reference_nodes:
                            st.write(node_info)
                
                # ä¿å­˜å†å²è®°å½•
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_answer,
                    "thinking": "\n".join(thinking_parts),
                    "nodes": all_reference_nodes
                })

# é€‰é¡¹å¡ 4: å‘é‡ç´¢å¼•ç®¡ç†
with tab4:
    st.header("å‘é‡ç´¢å¼•ç®¡ç†")

    # å‡å°‘ metric ç»„ä»¶ä¸‹æ–¹çš„ç©ºç™½
    st.markdown("""
    <style>
        [data-testid="stMetric"] {
            padding: 10px 0;
        }
        [data-testid="stMetric"] > div {
            padding: 0;
        }
    </style>
    """, unsafe_allow_html=True)

    # è·å–çŸ¥è¯†åº“ç®¡ç†å™¨å’Œå¤šçŸ¥è¯†åº“å‘é‡ç´¢å¼•
    kb_manager_tab3 = get_kb_manager()
    kb_list_tab3 = kb_manager_tab3.list_all()

    from pageindex.vector_index import get_multi_kb_vector_index
    multi_kb_index_tab3 = get_multi_kb_vector_index()

    # è®¡ç®—æ‰€æœ‰çŸ¥è¯†åº“çš„æ€»ç»Ÿè®¡ä¿¡æ¯
    total_kb_count = len(kb_list_tab3)
    total_nodes_all = 0
    total_docs_all = 0

    for kb in kb_list_tab3:
        try:
            kb_chroma_dir = kb_manager_tab3.get_chroma_dir(kb.id)
            stats = multi_kb_index_tab3.get_stats(kb.id, kb_chroma_dir)
            total_nodes_all += stats.get("total_nodes", 0)
            total_docs_all += stats.get("total_documents", 0)
        except Exception:
            pass

    # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡ä¿¡æ¯ï¼ˆç´§å‡‘å¸ƒå±€ï¼‰
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»çŸ¥è¯†åº“æ•°", total_kb_count)
    with col2:
        st.metric("æ€»ç´¢å¼•æ–‡æ¡£æ•°", total_docs_all)
    with col3:
        st.metric("æ€»èŠ‚ç‚¹æ•°", total_nodes_all)

    st.markdown("---")

    if not kb_list_tab3:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ã€ŒçŸ¥è¯†åº“ç®¡ç†ã€é€‰é¡¹å¡ä¸­åˆ›å»ºçŸ¥è¯†åº“ã€‚")
    else:
        # çŸ¥è¯†åº“ä¸‹æ‹‰é€‰æ¡†
        kb_options_tab3 = {f"{kb.name} ({kb.id})": kb.id for kb in kb_list_tab3}
        selected_kb_display_tab3 = st.selectbox(
            "é€‰æ‹©çŸ¥è¯†åº“",
            options=list(kb_options_tab3.keys()),
            key="vector_index_kb_selector",
            help="é€‰æ‹©è¦æŸ¥çœ‹å’Œç®¡ç†çš„çŸ¥è¯†åº“"
        )
        selected_kb_id_tab3 = kb_options_tab3[selected_kb_display_tab3]

        # è·å–é€‰ä¸­çŸ¥è¯†åº“çš„ç»Ÿè®¡ä¿¡æ¯
        kb_chroma_dir_tab3 = kb_manager_tab3.get_chroma_dir(selected_kb_id_tab3)
        kb_results_dir_tab3 = kb_manager_tab3.get_results_dir(selected_kb_id_tab3)

        try:
            kb_stats = multi_kb_index_tab3.get_stats(selected_kb_id_tab3, kb_chroma_dir_tab3)

            # æ˜¾ç¤ºé€‰ä¸­çŸ¥è¯†åº“çš„ç»Ÿè®¡
            col_a, col_b = st.columns(2)
            with col_a:
                st.metric("è¯¥çŸ¥è¯†åº“èŠ‚ç‚¹æ•°", kb_stats.get("total_nodes", 0))
            with col_b:
                st.metric("è¯¥çŸ¥è¯†åº“æ–‡æ¡£æ•°", kb_stats.get("total_documents", 0))

            # æ˜¾ç¤ºå·²ç´¢å¼•æ–‡æ¡£åˆ—è¡¨
            docs = kb_stats.get("documents", [])
            if docs:
                st.subheader(f"å·²ç´¢å¼•æ–‡æ¡£åˆ—è¡¨ - {selected_kb_display_tab3}")
                for doc in docs:
                    node_count = multi_kb_index_tab3.get_document_node_count(
                        selected_kb_id_tab3, kb_chroma_dir_tab3, doc
                    )
                    st.write(f"- **{doc}**: {node_count} ä¸ªèŠ‚ç‚¹")
            else:
                st.info("è¯¥çŸ¥è¯†åº“æš‚æ— å·²ç´¢å¼•çš„æ–‡æ¡£ã€‚")
        except Exception as e:
            st.error(f"è·å–ç´¢å¼•ç»Ÿè®¡å¤±è´¥: {e}")

        st.markdown("---")

        # ç´¢å¼•æ“ä½œï¼ˆé’ˆå¯¹é€‰ä¸­çš„çŸ¥è¯†åº“ï¼‰
        col_rebuild, col_clear = st.columns(2)

        with col_rebuild:
            if st.button("ğŸ”„ é‡å»ºè¯¥çŸ¥è¯†åº“ç´¢å¼•", type="primary", key="rebuild_kb_index"):
                with st.spinner(f"æ­£åœ¨é‡å»º [{selected_kb_id_tab3}] çš„ç´¢å¼•..."):
                    try:
                        # è·å–è¯¥çŸ¥è¯†åº“çš„ç»“æ„æ–‡ä»¶ç›®å½•
                        structure_files = []
                        if os.path.exists(kb_results_dir_tab3):
                            structure_files = [f for f in os.listdir(kb_results_dir_tab3) if f.endswith("_structure.json")]

                        if not structure_files:
                            st.warning("è¯¥çŸ¥è¯†åº“æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç»“æ„æ–‡ä»¶")
                        else:
                            progress = st.progress(0)
                            rebuilt_count = 0

                            for i, filename in enumerate(structure_files):
                                try:
                                    filepath = os.path.join(kb_results_dir_tab3, filename)
                                    with open(filepath, "r", encoding="utf-8") as f:
                                        data = json.load(f)

                                    doc_name = data.get("doc_name", filename.replace("_structure.json", ""))
                                    doc_description = data.get("doc_description", "")
                                    structure = data.get("structure", [])

                                    multi_kb_index_tab3.add_document(
                                        selected_kb_id_tab3, kb_chroma_dir_tab3,
                                        doc_name, structure, doc_description
                                    )
                                    rebuilt_count += 1

                                except Exception as e:
                                    st.warning(f"é‡å»º {filename} å¤±è´¥: {e}")

                                progress.progress((i + 1) / len(structure_files))

                            st.success(f"âœ… ç´¢å¼•é‡å»ºå®Œæˆï¼å…±å¤„ç† {rebuilt_count} ä¸ªæ–‡æ¡£")
                            st.rerun()

                    except Exception as e:
                        st.error(f"é‡å»ºç´¢å¼•å¤±è´¥: {e}")

        with col_clear:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºè¯¥çŸ¥è¯†åº“ç´¢å¼•", type="secondary", key="clear_kb_index"):
                try:
                    docs = multi_kb_index_tab3.get_all_documents(selected_kb_id_tab3, kb_chroma_dir_tab3)

                    for doc in docs:
                        multi_kb_index_tab3.delete_document(selected_kb_id_tab3, kb_chroma_dir_tab3, doc)

                    st.success(f"âœ… å·²æ¸…ç©º [{selected_kb_id_tab3}] çš„ {len(docs)} ä¸ªæ–‡æ¡£ç´¢å¼•")
                    st.rerun()
                except Exception as e:
                    st.error(f"æ¸…ç©ºç´¢å¼•å¤±è´¥: {e}")

    # Embedding æ¨¡å‹é…ç½®ä¿¡æ¯
    st.markdown("---")
    st.subheader("Embedding æ¨¡å‹é…ç½®")

    embedding_model_name = os.getenv("EMBEDDING_MODEL_NAME", "bge-m3:latest")
    embedding_api_url = os.getenv("EMBEDDING_MODEL_API_URL", "http://10.20.2.135:11434")

    st.code(f"""
EMBEDDING_MODEL_NAME={embedding_model_name}
EMBEDDING_MODEL_API_URL={embedding_api_url}
EMBEDDING_MODEL_TYPE=ollama
    """, language="bash")

    # æµ‹è¯• Embedding è¿æ¥
    if st.button("ğŸ”— æµ‹è¯• Embedding è¿æ¥"):
        with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
            try:
                from pageindex.vector_index import OllamaEmbedding
                embedding_model = OllamaEmbedding()
                test_embedding = embedding_model.embed("æµ‹è¯•æ–‡æœ¬")
                st.success(f"âœ… è¿æ¥æˆåŠŸï¼Embedding ç»´åº¦: {len(test_embedding)}")
            except Exception as e:
                st.error(f"âŒ è¿æ¥ å¤±è´¥: {e}")

# é€‰é¡¹å¡ 3: çŸ¥è¯†åº“ç®¡ç†
with tab3:
    st.header("çŸ¥è¯†åº“ç®¡ç†")

    # è·å–çŸ¥è¯†åº“ç®¡ç†å™¨
    kb_manager = get_kb_manager()

    # åˆ›å»ºçŸ¥è¯†åº“åŒºåŸŸ
    st.subheader("åˆ›å»ºæ–°çŸ¥è¯†åº“")
    with st.form("create_kb_form"):
        col1, col2 = st.columns(2)
        with col1:
            new_kb_id = st.text_input(
                "çŸ¥è¯†åº“ID",
                placeholder="ä¾‹å¦‚: tech_docs",
                help="åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿ï¼Œåˆ›å»ºåä¸å¯ä¿®æ”¹"
            )
        with col2:
            new_kb_name = st.text_input(
                "çŸ¥è¯†åº“åç§°",
                placeholder="ä¾‹å¦‚: æŠ€æœ¯æ–‡æ¡£åº“",
                help="ç”¨äºæ˜¾ç¤ºçš„ä¸­æ–‡åç§°"
            )
        new_kb_desc = st.text_area(
            "çŸ¥è¯†åº“æè¿°",
            placeholder="è¯·è¾“å…¥çŸ¥è¯†åº“çš„ç”¨é€”è¯´æ˜...",
            height=80
        )

        submitted = st.form_submit_button("â• åˆ›å»ºçŸ¥è¯†åº“", type="primary")
        if submitted:
            if not new_kb_id:
                st.error("è¯·è¾“å…¥çŸ¥è¯†åº“ID")
            elif not new_kb_name:
                st.error("è¯·è¾“å…¥çŸ¥è¯†åº“åç§°")
            else:
                try:
                    kb_info = kb_manager.create(new_kb_id, new_kb_name, new_kb_desc)
                    st.session_state.kb_create_success = kb_info.name
                    st.rerun()
                except ValueError as e:
                    st.error(f"åˆ›å»ºå¤±è´¥: {e}")
                except Exception as e:
                    st.error(f"åˆ›å»ºå¤±è´¥: {e}")

    # åˆ›å»ºæˆåŠŸå¼¹çª—
    if st.session_state.get("kb_create_success"):
        @st.dialog("åˆ›å»ºæˆåŠŸ")
        def show_success_dialog():
            st.success(f"âœ… çŸ¥è¯†åº“ '{st.session_state.kb_create_success}' åˆ›å»ºæˆåŠŸï¼")
            if st.button("ç¡®å®š", type="primary"):
                st.session_state.kb_create_success = None
                st.rerun()
        show_success_dialog()

    st.markdown("---")

    # çŸ¥è¯†åº“åˆ—è¡¨
    st.subheader("çŸ¥è¯†åº“åˆ—è¡¨")
    kb_list = kb_manager.list_all()

    if kb_list:
        for kb in kb_list:
            with st.expander(f"ğŸ“š {kb.name} ({kb.id})", expanded=False):
                col1, col2, col3 = st.columns([2, 2, 1])
                with col1:
                    st.write(f"**ID:** {kb.id}")
                    st.write(f"**åç§°:** {kb.name}")
                with col2:
                    st.write(f"**åˆ›å»ºæ—¶é—´:** {kb.created_at[:10] if kb.created_at else 'æœªçŸ¥'}")
                    st.write(f"**æè¿°:** {kb.description or 'æ— '}")
                with col3:
                    # åˆ é™¤æŒ‰é’®ï¼ˆå¸¦ç¡®è®¤ï¼‰
                    if f"confirm_delete_{kb.id}" not in st.session_state:
                        st.session_state[f"confirm_delete_{kb.id}"] = False

                    if st.session_state[f"confirm_delete_{kb.id}"]:
                        st.warning("ç¡®è®¤åˆ é™¤ï¼Ÿ")
                        col_yes, col_no = st.columns(2)
                        with col_yes:
                            if st.button("æ˜¯", key=f"yes_{kb.id}", type="primary"):
                                kb_manager.delete(kb.id)
                                st.session_state[f"confirm_delete_{kb.id}"] = False
                                st.success(f"å·²åˆ é™¤çŸ¥è¯†åº“: {kb.name}")
                                st.rerun()
                        with col_no:
                            if st.button("å¦", key=f"no_{kb.id}"):
                                st.session_state[f"confirm_delete_{kb.id}"] = False
                                st.rerun()
                    else:
                        if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"del_{kb.id}", type="secondary"):
                            st.session_state[f"confirm_delete_{kb.id}"] = True
                            st.rerun()

                # æ˜¾ç¤ºçŸ¥è¯†åº“ç›®å½•ä¿¡æ¯
                st.caption(f"ä¸Šä¼ ç›®å½•: {kb_manager.get_uploads_dir(kb.id)}")
                st.caption(f"ç»“æ„ç›®å½•: {kb_manager.get_results_dir(kb.id)}")

        st.caption(f"å…± {len(kb_list)} ä¸ªçŸ¥è¯†åº“")
    else:
        st.info("æš‚æ— çŸ¥è¯†åº“ï¼Œè¯·åˆ›å»ºæ–°çš„çŸ¥è¯†åº“ã€‚")

# é€‰é¡¹å¡ 5: å‘é‡æ£€ç´¢
with tab5:
    # çŸ¥è¯†åº“å¤šé€‰
    kb_manager_tab5 = get_kb_manager()
    kb_list_tab5 = kb_manager_tab5.list_all()

    if not kb_list_tab5:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ã€ŒçŸ¥è¯†åº“ç®¡ç†ã€é€‰é¡¹å¡ä¸­åˆ›å»ºçŸ¥è¯†åº“å¹¶ä¸Šä¼ æ–‡æ¡£ã€‚")
    else:
        # çŸ¥è¯†åº“å¤é€‰æ¡†åˆ—è¡¨
        st.subheader("é€‰æ‹©æ£€ç´¢çš„çŸ¥è¯†åº“")

        # åˆå§‹åŒ–æ‰€æœ‰çŸ¥è¯†åº“çš„é€‰ä¸­çŠ¶æ€ï¼ˆé¦–æ¬¡åŠ è½½æ—¶é»˜è®¤é€‰ä¸­ï¼‰
        for kb in kb_list_tab5:
            if f"api_kb_cb_{kb.id}" not in st.session_state:
                st.session_state[f"api_kb_cb_{kb.id}"] = True

        # åˆå§‹åŒ–å…¨é€‰å¤é€‰æ¡†çŠ¶æ€
        if "api_select_all_kb_state" not in st.session_state:
            st.session_state.api_select_all_kb_state = True

        # å…¨é€‰å¤é€‰æ¡†å›è°ƒå‡½æ•°
        def on_api_select_all_change():
            new_value = st.session_state.api_select_all_kb_checkbox
            for kb in kb_list_tab5:
                st.session_state[f"api_kb_cb_{kb.id}"] = new_value
            st.session_state.api_select_all_kb_state = new_value

        # å…¨é€‰/å…¨ä¸é€‰ å¤é€‰æ¡†
        col_select_all, col_spacer = st.columns([1, 5])
        with col_select_all:
            st.checkbox(
                "å…¨é€‰",
                value=st.session_state.api_select_all_kb_state,
                key="api_select_all_kb_checkbox",
                on_change=on_api_select_all_change
            )

        # æ¨ªå‘æ’åˆ—çŸ¥è¯†åº“å¤é€‰æ¡†ï¼Œæ¯è¡Œ4åˆ—
        cols_per_row = 4
        api_kb_selections = {}

        for i in range(0, len(kb_list_tab5), cols_per_row):
            cols = st.columns(cols_per_row)
            for j, col in enumerate(cols):
                kb_idx = i + j
                if kb_idx < len(kb_list_tab5):
                    kb = kb_list_tab5[kb_idx]
                    with col:
                        api_kb_selections[kb.id] = st.checkbox(
                            f"ğŸ“š {kb.name}",
                            key=f"api_kb_cb_{kb.id}",
                            help=kb.id
                        )

        # æ›´æ–°å…¨é€‰çŠ¶æ€ï¼ˆæ ¹æ®å„çŸ¥è¯†åº“çš„å®é™…é€‰ä¸­çŠ¶æ€ï¼‰
        api_all_selected_now = all(api_kb_selections.values()) if api_kb_selections else True
        if api_all_selected_now != st.session_state.api_select_all_kb_state:
            st.session_state.api_select_all_kb_state = api_all_selected_now

        # è·å–é€‰ä¸­çš„çŸ¥è¯†åº“IDåˆ—è¡¨
        api_selected_kb_ids = [kb_id for kb_id, selected in api_kb_selections.items() if selected]

        if not api_selected_kb_ids:
            st.info("â„¹ï¸ æœªé€‰æ‹©çŸ¥è¯†åº“ï¼Œå°†æœç´¢æ‰€æœ‰çŸ¥è¯†åº“")
        else:
            st.success(f"âœ… å·²é€‰æ‹© {len(api_selected_kb_ids)} ä¸ªçŸ¥è¯†åº“")

        st.markdown("---")

        # API é…ç½®
        col_api, col_topk = st.columns([3, 1])
        with col_api:
            api_url = st.text_input(
                "API åœ°å€",
                value="http://localhost:8502/query/raw",
                key="api_test_url"
            )
        with col_topk:
            api_top_k = st.number_input(
                "Top K",
                min_value=1,
                max_value=50,
                value=10,
                key="api_test_topk"
            )

        # æŸ¥è¯¢è¾“å…¥
        api_query = st.text_input(
            "æŸ¥è¯¢å†…å®¹",
            placeholder="è¯·è¾“å…¥è¦æ£€ç´¢çš„é—®é¢˜...",
            key="api_test_query"
        )

        # å‘é€è¯·æ±‚æŒ‰é’®
        if st.button("ğŸš€ å‘é€è¯·æ±‚", type="primary", key="api_test_send"):
            if not api_query:
                st.error("è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹")
            else:
                import requests

                # æ„å»ºè¯·æ±‚ä½“ï¼ˆå¦‚æœæ²¡æœ‰é€‰æ‹©çŸ¥è¯†åº“ï¼Œåˆ™ä¸ä¼  kb_idsï¼ŒAPI ä¼šæœç´¢æ‰€æœ‰çŸ¥è¯†åº“ï¼‰
                request_body = {
                    "q": api_query,
                    "top_k": api_top_k
                }
                if api_selected_kb_ids:
                    request_body["kb_ids"] = api_selected_kb_ids

                # æ˜¾ç¤ºè¯·æ±‚ä¿¡æ¯
                with st.expander("ğŸ“¤ è¯·æ±‚è¯¦æƒ…", expanded=False):
                    st.code(f"POST {api_url}", language="text")
                    st.json(request_body)

                # å‘é€è¯·æ±‚
                with st.spinner("æ­£åœ¨è¯·æ±‚ API..."):
                    try:
                        response = requests.post(
                            api_url,
                            json=request_body,
                            timeout=60
                        )

                        # æ˜¾ç¤ºå“åº”çŠ¶æ€
                        if response.status_code == 200:
                            st.success(f"âœ… è¯·æ±‚æˆåŠŸ (HTTP {response.status_code})")
                        else:
                            st.error(f"âŒ è¯·æ±‚å¤±è´¥ (HTTP {response.status_code})")

                        # è§£æå“åº”
                        try:
                            response_data = response.json()

                            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                            if response_data.get("status") == "ok":
                                total_results = response_data.get("total_results", 0)
                                searched_kb = response_data.get("searched_kb", [])
                                st.info(f"ğŸ“Š æ£€ç´¢åˆ° {total_results} ä¸ªç»“æœï¼Œæ¥è‡ª {len(searched_kb)} ä¸ªçŸ¥è¯†åº“")

                            # æ˜¾ç¤ºç»“æœåˆ—è¡¨
                            results = response_data.get("results", [])
                            if results:
                                st.subheader("æ£€ç´¢ç»“æœ")
                                for i, result in enumerate(results):
                                    score = result.get("score", 0)
                                    title = result.get("title", "")
                                    kb_name = result.get("kb_name", "")
                                    doc_name = result.get("doc_name", "")
                                    summary = result.get("summary", "")
                                    text = result.get("text", "")

                                    with st.expander(
                                        f"#{i+1} [{kb_name}] {doc_name} - {title} (ç›¸ä¼¼åº¦: {score:.4f})",
                                        expanded=(i < 3)  # å‰3ä¸ªé»˜è®¤å±•å¼€
                                    ):
                                        st.write(f"**çŸ¥è¯†åº“:** {kb_name} ({result.get('kb_id', '')})")
                                        st.write(f"**æ–‡æ¡£:** {doc_name}")
                                        st.write(f"**èŠ‚ç‚¹ID:** {result.get('node_id', '')}")
                                        st.write(f"**ç›¸ä¼¼åº¦:** {score:.4f}")

                                        if summary:
                                            st.write("**æ‘˜è¦:**")
                                            st.markdown(f"> {summary}")

                                        if text:
                                            st.write("**åŸæ–‡å†…å®¹:**")
                                            st.text_area(
                                                "å†…å®¹",
                                                value=text[:2000] + ("..." if len(text) > 2000 else ""),
                                                height=200,
                                                key=f"api_result_text_{i}",
                                                label_visibility="collapsed"
                                            )

                            # æ˜¾ç¤ºå®Œæ•´å“åº” JSON
                            with st.expander("ğŸ“¥ å®Œæ•´å“åº” JSON", expanded=False):
                                st.json(response_data)

                        except Exception as e:
                            st.error(f"è§£æå“åº”å¤±è´¥: {e}")
                            st.text(response.text)

                    except requests.exceptions.ConnectionError:
                        st.error("âŒ è¿æ¥å¤±è´¥ï¼Œè¯·ç¡®ä¿ API æœåŠ¡å·²å¯åŠ¨ (python api.py)")
                    except requests.exceptions.Timeout:
                        st.error("âŒ è¯·æ±‚è¶…æ—¶")
                    except Exception as e:
                        st.error(f"âŒ è¯·æ±‚å¤±è´¥: {e}")

st.markdown("---")
st.caption("ç”± PageIndex æ¡†æ¶é©±åŠ¨ - æ··åˆå‘é‡æ£€ç´¢ RAG")
